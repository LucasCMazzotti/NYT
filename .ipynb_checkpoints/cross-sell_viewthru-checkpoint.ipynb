{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data stuff\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "#regression stuff\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#graph stuff\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objects as go\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "GenericGBQException",
     "evalue": "Reason: 404 Not found: Project nyt-oct-prd\n\n(job ID: b70e69fc-141c-4a27-b5b5-729c6e5bb4ab)\n\n                         -----Query Job SQL Follows-----                          \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:SELECT *\n   3:FROM `nyt-oct-prd.twigeo.twigeo_games`\n   4:where lower(campaign_name) = '2020_tg_game_app_cpi3_ios_us_mot_pros_20201123'\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36m_download_results\u001b[0;34m(self, query_job, max_results, progress_bar_type, user_dtypes)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0;31m# Get the table schema, so that we can list rows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDEFAULT_RETRY\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"retry\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 Not found: Project nyt-oct-prd\n\n(job ID: b70e69fc-141c-4a27-b5b5-729c6e5bb4ab)\n\n                         -----Query Job SQL Follows-----                          \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:SELECT *\n   3:FROM `nyt-oct-prd.twigeo.twigeo_games`\n   4:where lower(campaign_name) = '2020_tg_game_app_cpi3_ios_us_mot_pros_20201123'\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGenericGBQException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-57d5b775c2ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m '''\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m test = pd.read_gbq(q,\n\u001b[0m\u001b[1;32m      8\u001b[0m                  \u001b[0mproject_id\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'nyt-bigquery-beta-workspace'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                  \u001b[0mdialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'standard'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/gbq.py\u001b[0m in \u001b[0;36mread_gbq\u001b[0;34m(query, project_id, index_col, col_order, reauth, auth_local_webserver, dialect, location, configuration, credentials, use_bqstorage_api, max_results, private_key, verbose, progress_bar_type)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# END: new kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     return pandas_gbq.read_gbq(\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mproject_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mread_gbq\u001b[0;34m(query, project_id, index_col, col_order, reauth, auth_local_webserver, dialect, location, configuration, credentials, use_bqstorage_api, max_results, verbose, private_key, progress_bar_type, dtypes)\u001b[0m\n\u001b[1;32m    970\u001b[0m     )\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m     final_df = connector.run_query(\n\u001b[0m\u001b[1;32m    973\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mconfiguration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(self, query, max_results, progress_bar_type, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mdtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         return self._download_results(\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0mquery_reply\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36m_download_results\u001b[0;34m(self, query_job, max_results, progress_bar_type, user_dtypes)\u001b[0m\n\u001b[1;32m    591\u001b[0m             )\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_error\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_http_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mprocess_http_error\u001b[0;34m(ex)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m# <https://cloud.google.com/bigquery/troubleshooting-errors>`__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mGenericGBQException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reason: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     def run_query(\n",
      "\u001b[0;31mGenericGBQException\u001b[0m: Reason: 404 Not found: Project nyt-oct-prd\n\n(job ID: b70e69fc-141c-4a27-b5b5-729c6e5bb4ab)\n\n                         -----Query Job SQL Follows-----                          \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:SELECT *\n   3:FROM `nyt-oct-prd.twigeo.twigeo_games`\n   4:where lower(campaign_name) = '2020_tg_game_app_cpi3_ios_us_mot_pros_20201123'\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |"
     ]
    }
   ],
   "source": [
    "q = '''\n",
    "SELECT *\n",
    "FROM `nyt-octopus-prd.twigeo.twigeo_games`\n",
    "where lower(campaign_name) = '2020_tg_game_app_cpi3_ios_us_mot_pros_20201123'\n",
    "'''\n",
    "\n",
    "test = pd.read_gbq(q,\n",
    "                 project_id ='nyt-bigquery-beta-workspace',\n",
    "                 dialect='standard',\n",
    "                 verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_match</th>\n",
       "      <th>account</th>\n",
       "      <th>account_id</th>\n",
       "      <th>attr_window</th>\n",
       "      <th>bid_type</th>\n",
       "      <th>buying_type</th>\n",
       "      <th>campaign</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>campaign_objective</th>\n",
       "      <th>channel</th>\n",
       "      <th>clicks</th>\n",
       "      <th>conversions</th>\n",
       "      <th>creative_concept</th>\n",
       "      <th>creative_file_type</th>\n",
       "      <th>creative_version</th>\n",
       "      <th>data_source</th>\n",
       "      <th>date</th>\n",
       "      <th>funnel_depth_category</th>\n",
       "      <th>impressions</th>\n",
       "      <th>kdip</th>\n",
       "      <th>marketing_geography</th>\n",
       "      <th>marketing_initiative</th>\n",
       "      <th>marketing_segment</th>\n",
       "      <th>marketing_subinitiative</th>\n",
       "      <th>placement</th>\n",
       "      <th>placement_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>site</th>\n",
       "      <th>sor_prod</th>\n",
       "      <th>spend</th>\n",
       "      <th>targeting_data_categorya</th>\n",
       "      <th>targeting_data_categoryb</th>\n",
       "      <th>targeting_data_description</th>\n",
       "      <th>targeting_data_providera</th>\n",
       "      <th>targeting_data_providerb</th>\n",
       "      <th>targeting_geography</th>\n",
       "      <th>time_code</th>\n",
       "      <th>adlabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_match, account, account_id, attr_window, bid_type, buying_type, campaign, campaign_id, campaign_objective, channel, clicks, conversions, creative_concept, creative_file_type, creative_version, data_source, date, funnel_depth_category, impressions, kdip, marketing_geography, marketing_initiative, marketing_segment, marketing_subinitiative, placement, placement_id, platform, site, sor_prod, spend, targeting_data_categorya, targeting_data_categoryb, targeting_data_description, targeting_data_providera, targeting_data_providerb, targeting_geography, time_code, adlabels]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define functions for easier plotting__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variables_func(df,plot_list, one_plot=False, title=None, monthly=False):\n",
    "    if monthly == False:\n",
    "        x = pd.date_range(df.index.min(), df.index.max())\n",
    "        y_df = df.copy()\n",
    "        y_df = y_df.reindex(x)\n",
    "        plot_me = plot_list\n",
    "        data = []\n",
    "        palette =[\n",
    "        '#1f77b4',  # muted blue\n",
    "        '#ff7f0e',  # safety orange\n",
    "        '#7f7f7f',  # middle gray\n",
    "        '#2ca02c',  # cooked asparagus green\n",
    "        '#d62728',  # brick red\n",
    "        '#9467bd',  # muted purple\n",
    "        '#8c564b',  # chestnut brown\n",
    "        '#e377c2', # raspberry yogurt pink\n",
    "        '#1f77b4',  # muted blue\n",
    "        '#ff7f0e',  # safety orange\n",
    "        '#7f7f7f',  # middle gray\n",
    "        '#2ca02c',  # cooked asparagus green\n",
    "        '#d62728',  # brick red\n",
    "        '#9467bd',  # muted purple\n",
    "        '#8c564b',  # chestnut brown\n",
    "        '#e377c2', # raspberry yogurt pink\n",
    "        '#1f77b4',  # muted blue\n",
    "        '#ff7f0e',  # safety orange\n",
    "        '#7f7f7f',  # middle gray\n",
    "        '#2ca02c',  # cooked asparagus green\n",
    "        '#d62728',  # brick red\n",
    "        '#9467bd',  # muted purple\n",
    "        '#8c564b',  # chestnut brown\n",
    "        '#e377c2', # raspberry yogurt pink\n",
    "        '#1f77b4',  # muted blue\n",
    "        '#ff7f0e',  # safety orange\n",
    "        '#7f7f7f',  # middle gray\n",
    "        '#2ca02c',  # cooked asparagus green\n",
    "        '#d62728',  # brick red\n",
    "        '#9467bd',  # muted purple\n",
    "        '#8c564b',  # chestnut brown\n",
    "        '#e377c2', # raspberry yogurt pink\n",
    "        ]\n",
    "\n",
    "        for i in range(len(plot_me)):\n",
    "            # Create a trace\n",
    "            trace = go.Scatter(\n",
    "                x = df.index,\n",
    "                y = df.loc[:,plot_me[i]],\n",
    "                name = plot_me[i],\n",
    "                line = dict(color = palette[i])\n",
    "            )\n",
    "\n",
    "            if one_plot == False:\n",
    "                data = [trace]\n",
    "                layout=go.Layout(title=plot_me[i])\n",
    "\n",
    "                plotly.offline.iplot(go.Figure(data=data, layout=layout), filename='basic-line')\n",
    "            else:\n",
    "                data.append(trace)\n",
    "\n",
    "        if one_plot == True:\n",
    "            layout=go.Layout(title=title,\n",
    "                            legend=dict(orientation='h',xanchor = \"center\",x = 0.5))\n",
    "            plotly.offline.iplot(go.Figure(data=data, layout = layout), filename='scatter-mode')\n",
    "    else:\n",
    "        aggre = {plot_list[i]:'sum' for i in range(len(plot_list))}\n",
    "        if isinstance(df.index, pd.DatetimeIndex) == False:\n",
    "            df_m = df.set_index('dte').groupby(pd.Grouper(freq='M')).agg(aggre)\n",
    "        else:\n",
    "            df_m = df.groupby(pd.Grouper(freq='M')).agg(aggre)\n",
    "\n",
    "        plot_me = plot_list\n",
    "        data = []\n",
    "        for i in range(len(plot_me)):\n",
    "            # Create a trace\n",
    "            trace = go.Scatter(\n",
    "                x = df_m.index,\n",
    "                y = df_m.loc[:,plot_me[i]],\n",
    "                name = plot_me[i]\n",
    "            )\n",
    "\n",
    "            if one_plot == False:\n",
    "                data = [trace]\n",
    "                layout=go.Layout(title=plot_me[i])\n",
    "                plotly.offline.iplot(go.Figure(data=data, layout=layout), filename='basic-line')\n",
    "            else:\n",
    "                data.append(trace)\n",
    "\n",
    "        if one_plot == True:\n",
    "            plotly.offline.iplot(go.Figure(data=data), filename='scatter-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variables(df, plot_list, one_plot=False, title=None, monthly=False, scaled=False):\n",
    "    if scaled == True:\n",
    "        df_scale = df[plot_list]\n",
    "        for col in df_scale.columns:\n",
    "            x = df_scale[[col]].values.astype(float)\n",
    "            min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "            df_scale[col] = x_scaled\n",
    "        plot_variables_func(df_scale, plot_list, one_plot=one_plot, title=title, monthly=monthly)\n",
    "    else:\n",
    "        plot_variables_func(df, plot_list, one_plot=one_plot, title=title, monthly=monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__function for corr matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(df, var_list, start, end, fontsize=12):\n",
    "\n",
    "#     label_list = [x.partition('_adstock')[0] for x in var_list]\n",
    "#     label_list = [x.partition('_impressions')[0] for x in label_list]\n",
    "#     label_list = [x.replace(\"fixed\",\" \") for x in label_list]\n",
    "#     label_list = [x.replace(\"_\",\" \").title() for x in label_list]\n",
    "    label_list = var_list\n",
    "\n",
    "\n",
    "    corr = df.loc[start:end][var_list].corr()\n",
    "\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(15, 12))\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    sns.heatmap(corr, \n",
    "#                 xticklabels=label_list, \n",
    "#                 yticklabels=label_list, \n",
    "                mask=mask, \n",
    "                cmap=cmap, \n",
    "                vmin=-1,\n",
    "                vmax=1, \n",
    "                center=0,\n",
    "                square=True, \n",
    "                linewidths=.5, \n",
    "                annot=True, \n",
    "                annot_kws={\"size\":fontsize}, \n",
    "                fmt='.1g'\n",
    "               )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Read in PMD Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When running back to 2016 or so this costs 90GB, running back through beginning of 2020 costs about 25GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a936ed4d7ec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m df = pd.read_gbq(q,\n\u001b[0m\u001b[1;32m     41\u001b[0m                  \u001b[0mproject_id\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'nyt-bigquery-beta-workspace'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                  \u001b[0mdialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'standard'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/gbq.py\u001b[0m in \u001b[0;36mread_gbq\u001b[0;34m(query, project_id, index_col, col_order, reauth, auth_local_webserver, dialect, location, configuration, credentials, use_bqstorage_api, max_results, private_key, verbose, progress_bar_type)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# END: new kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     return pandas_gbq.read_gbq(\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mproject_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mread_gbq\u001b[0;34m(query, project_id, index_col, col_order, reauth, auth_local_webserver, dialect, location, configuration, credentials, use_bqstorage_api, max_results, verbose, private_key, progress_bar_type, dtypes)\u001b[0m\n\u001b[1;32m    970\u001b[0m     )\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m     final_df = connector.run_query(\n\u001b[0m\u001b[1;32m    973\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mconfiguration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(self, query, max_results, progress_bar_type, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mdtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         return self._download_results(\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0mquery_reply\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36m_download_results\u001b[0;34m(self, query_job, max_results, progress_bar_type, user_dtypes)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0mconversion_dtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_bqschema_to_nullsafe_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0mconversion_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m             df = rows_iter.to_dataframe(\n\u001b[0m\u001b[1;32m    588\u001b[0m                 \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconversion_dtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m                 \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, date_as_object)\u001b[0m\n\u001b[1;32m   1765\u001b[0m             \u001b[0mbqstorage_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m         record_batch = self.to_arrow(\n\u001b[0m\u001b[1;32m   1768\u001b[0m             \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36mto_arrow\u001b[0;34m(self, progress_bar_type, bqstorage_client, create_bqstorage_client)\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mrecord_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             for record_batch in self._to_arrow_iterable(\n\u001b[0m\u001b[1;32m   1600\u001b[0m                 \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m             ):\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36m_to_page_iterable\u001b[0;34m(self, bqstorage_download, tabledata_list_download, bqstorage_client)\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtabledata_list_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/_pandas_helpers.py\u001b[0m in \u001b[0;36mdownload_arrow_row_iterator\u001b[0;34m(pages, bq_schema)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0marrow_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbq_to_arrow_data_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbq_schema\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0m_row_iterator_page_to_arrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrow_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/api_core/page_iterator.py\u001b[0m in \u001b[0;36m_page_iter\u001b[0;34m(self, increment)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mPage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meach\u001b[0m \u001b[0mpage\u001b[0m \u001b[0mof\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \"\"\"\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/api_core/page_iterator.py\u001b[0m in \u001b[0;36m_next_page\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_next_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_page_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_to_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_page\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36m_get_next_page_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1470\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"startIndex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"maxResults\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_page_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m         return self.api_request(\n\u001b[0m\u001b[1;32m   1473\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_HTTP_METHOD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m             ):\n\u001b[1;32m    643\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_RETRY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             )\n\u001b[0;32m--> 281\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    282\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         response = self._make_request(\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, method, url, data, content_type, headers, target_object, timeout)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         return self._do_request(\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36m_do_request\u001b[0;34m(self, method, url, headers, data, target_object, timeout)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mHTTP\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m--> 329\u001b[0;31m         return self.http.request(\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    465\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    424\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "q = '''\n",
    "SELECT \n",
    "     account\n",
    "    , attr_window\n",
    "    , campaign\n",
    "    , _match\n",
    "    , campaign_objective\n",
    "    , date\n",
    "    , marketing_initiative\n",
    "    , marketing_segment\n",
    "    , marketing_subinitiative\n",
    "    , channel\n",
    "    , platform\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then spend else 0 end) spend\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then clicks else 0 end) clicks\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then impressions else 0 end) impressions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Core' then conversions else null end) digi_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Crosswords' then conversions else null end) games_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'EDU' then conversions else null end) edu_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Home Delivery' then conversions else null end) hd_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'CK' then conversions else null end) ck_conversions     \n",
    "    , sum(case\n",
    "            when sor_prod = 'Core All (Core, HD, EDU)' then conversions else null end) core_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'All (Core All, NPV)' then conversions else null end) all_conversions\n",
    "FROM `nyt-mkt-prd.paid_media_data.placement_daily_vw`\n",
    "WHERE date >= '2016-01-01' and attr_window in('Combined')\n",
    "group by 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\n",
    "order by date, campaign, _match\n",
    "\n",
    "'''\n",
    "\n",
    "start_time = time.time() \n",
    "\n",
    "df = pd.read_gbq(q,\n",
    "                 project_id ='nyt-bigquery-beta-workspace',\n",
    "                 dialect='standard',\n",
    "                 verbose=False)\n",
    "\n",
    "print(f'time took: {str(round(time.time() - start_time, 2))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on use of attribution window:\n",
    "* Use the same attr_window for each channel\n",
    "* Media team right now uses _combined_ attr_window, which is mostly Media Reported but some quirks\n",
    "* For this analysis, we should use:\n",
    "    * __Combined__ and __Media Reported - Click Thru__\n",
    "* Do one version that looks only at Media Reported click thru and one version that looks at combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "the below is no longer needed - I had terrible wifi in Puerto Rico so had to chunk the data pull\n",
    "'''\n",
    "# increment=200000\n",
    "# chunks=list(range(0, 1838251, increment))\n",
    "\n",
    "# chunks[-1]+=increment \n",
    "# intervals=[[chunks[i-1], chunks[i]+1] for i, e in enumerate(chunks) if i > 0]\n",
    "\n",
    "# query_str='''\n",
    "# select * from `nyt-bigquery-beta-workspace.lucas_data.pmd_data_jan_20_to_apr_21`\n",
    "# order by 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21 limit {end} offset {start}\n",
    "# '''\n",
    "\n",
    "# df = pd.DataFrame() \n",
    "\n",
    "# for start, end in intervals:  \n",
    "#     q = query_str.format(start=start, end=end)\n",
    "#     print(f\"running query: {q}\")\n",
    "#     start_time = time.time()  \n",
    "#     temp_df = pd.read_gbq(q,\n",
    "#                  project_id ='nyt-bigquery-beta-workspace',\n",
    "#                  dialect='standard',\n",
    "#                  verbose=False)\n",
    "#     print(f'time took: {str(round(time.time() - start_time, 2))}')\n",
    "#     df = pd.concat([df, temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep a copy of the original just to be safe\n",
    "df_safe = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_safe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idk why there's duplicates but there are... so drop them\n",
    "print(f\"Rows before duplicates removed: {df.shape[0]}\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Rows after duplicates removed: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('all_pmd_data_jan_20_to_apr_21.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKPOINT: read in data from CSV here if needed. Begin to limit data to just Core media activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some Twigeo campaigns don't get recognized as Games campaigns in PMD, manually correct those\n",
    "df.loc[(df['marketing_subinitiative'] == 'X-UNKNOWN-X') & \n",
    "       (\n",
    "          (df['campaign'].str.contains('game')) | \n",
    "          (df['campaign'].str.contains('xwd')) | \n",
    "          (df['campaign'].str.contains('cross'))\n",
    "       ), 'marketing_subinitiative'] = 'Games (former: Crosswords)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit to Core campaigns \n",
    "df_core = df[df['marketing_subinitiative'].isin(['Core','CORE Business'])]\n",
    "\n",
    "#remove mobile partners - conversion data is unreliable in PMD\n",
    "df_core = df_core[~(df_core['account'].str.contains('Twigeo')) & \n",
    "                 ~(df_core['account'] == 'The New York Times App')]\n",
    "\n",
    "#remove app install and app-based campaigns so we focus only on web\n",
    "df_core['campaign'] = df_core['campaign'].str.lower()\n",
    "df_core = df_core[~df_core['campaign'].str.contains('app')]\n",
    "\n",
    "#limit attribution window to media-reported. We may want to reexamine this analysis in the future using other windows\n",
    "#such as 7d-all or 1d-all\n",
    "df_core = df_core[df_core['attr_window'] == 'Combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create date-based aggregation columns for easier grouping\n",
    "df_core['year_month_cal'] = df_core['date'].dt.strftime('%Y-%m')\n",
    "df_core['year_week_iso'] = df_core['date'].dt.strftime('%GW%V')\n",
    "df_core['year_week_monday'] = df_core['date'].dt.to_period('W').apply(lambda r: r.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a composite channel-marketing-initiative column for a pd.melt\n",
    "df_core['channel_mkt_init'] = df_core['channel'] + \" - \" + df_core['marketing_initiative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Top level analysis on Core-to-SPG cross sell (Core campaigns driving CK or Games starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#understand overall impact 1 Jan 2020 - 7 Apr 2021\n",
    "df_core[['core_conversions','games_conversions','ck_conversions']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Since January 2020, web-based Core media (note: this analysis excludes app-based media) has generated 845k starts. It has also enerated 13.5k Games starts and 31.3k Cooking starts which have never been recognized!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most recent 5 year LTVs I found for Cooking and Games are as follows: \n",
    "* Cooking: $124\n",
    "\n",
    "* Games: $97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sums = df_core[['core_conversions','games_conversions','ck_conversions']].sum().to_frame()\n",
    "games_val = start_sums.loc['games_conversions'][0] * 97\n",
    "ck_val = start_sums.loc['ck_conversions'][0] * 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Games added value: {round(games_val, 2)}')\n",
    "print(f'CK added value: {round(ck_val, 2)}')\n",
    "print(f'Combined value: {round(games_val + ck_val, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means upon initial glance, web-based campaigns since Jan 2020 have generated nearly $5.2M in unrecognized value based on media reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core['spg_conversions'] = df_core['games_conversions'] + df_core['ck_conversions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create monthly view of impressions, core starts, spg starts\n",
    "core_plt = df_core.groupby('year_week_monday')['spend','impressions','core_conversions','spg_conversions',\n",
    "                                         'ck_conversions','games_conversions'].sum()\n",
    "\n",
    "#rename cols\n",
    "core_plt.rename(columns = {'spend':'core_spend', \n",
    "                           'impressions':'core_impressions'},inplace=True)\n",
    "\n",
    "plot_variables(core_plt, ['core_spend','core_impressions','core_conversions','spg_conversions',\n",
    "                     'ck_conversions','games_conversions'], one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's some relationship between Core impressions and SPG starts. Let's also layer in SPG impressions + spend to see whether that's having an effect as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__add spg spend and impressions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spg_df = df[(df['marketing_subinitiative'].isin(['Cooking','Games'])) & \n",
    "  ~(df['campaign'].str.contains('app'))]\n",
    "\n",
    "spg_df['year_month_cal'] = spg_df['date'].dt.strftime('%Y-%m')\n",
    "spg_df['year_week_iso'] = spg_df['date'].dt.strftime('%GW%V')\n",
    "\n",
    "spg_df['year_week_monday'] = spg_df['date'].dt.to_period('W').apply(lambda r: r.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create summary to merge with plt\n",
    "spg_df = spg_df.groupby('year_week_monday')['spend','impressions'].sum()\n",
    "spg_df.rename(columns = {'spend':'spg_spend',\n",
    "                        'impressions':'spg_impressions'}, \n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_plt.reset_index(inplace=True)\n",
    "spg_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge core and spg data\n",
    "plt_merged = core_plt.merge(spg_df, how='left', on='year_week_monday').set_index('year_week_monday')\n",
    "\n",
    "#get rid of nulls\n",
    "plt_merged.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr_matrix(plt_merged, plt_merged.columns.values, start=plt_merged.index.values.min(), end=plt_merged.index.values.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(plt_merged, plt_merged.columns, one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. look for more granular correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correls_df = df_core.groupby(['year_month_cal','year_week_iso','date','channel_mkt_init']).sum().reset_index()\n",
    "correls_df = correls_df.pivot(index='date', columns='channel_mkt_init', values=['clicks','impressions','games_conversions','ck_conversions', 'spg_conversions'])\n",
    "\n",
    "correls_df.columns = ['_'.join(col).strip() for col in correls_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correls_df.columns = correls_df.columns.str.replace(' - ','_').str.replace('/','').str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core['channel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correls_df[[col for col in correls_df.columns if 'Native' in col and 'ck_conversions' not in col and 'games_conversions' not in col]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(correls_df, ['clicks_Native_Sale','impressions_Native_Sale','spg_conversions_Native_Sale'], one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Try regression - with all data and impression volumes across channel_mkt_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__construct impressions, clicks, and starts columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = df_core.groupby(['date','channel_mkt_init'])['clicks','impressions','spend','core_conversions','spg_conversions'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = reg_df.pivot(index='date', columns='channel_mkt_init', values=['clicks','impressions','spend','core_conversions','spg_conversions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.columns = reg_df.columns = ['_'.join(col).strip() for col in reg_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.reset_index(inplace=True)\n",
    "reg_df['date'] = reg_df['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df['spg_conversions_all'] = reg_df[[col for col in reg_df.columns if 'spg_conversions' in col]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create month and weekday cols for dummies\n",
    "reg_df['weekday'] = reg_df['date'].apply(lambda x: x.strftime('%A'))\n",
    "reg_df['month'] = reg_df['date'].dt.month_name()\n",
    "\n",
    "#create a merge dummies \n",
    "reg_df = pd.concat([reg_df, \n",
    "               pd.get_dummies(reg_df['weekday'], prefix='weekday'), \n",
    "               pd.get_dummies(reg_df['month'], prefix='month')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__add spg impressions, spend information__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create reg_dfs from main data pull with only cooking and games data\n",
    "\n",
    "cooking_reg_df = df_safe[(df_safe['marketing_subinitiative'].isin(['Cooking'])) & \n",
    "                     ~(df_safe['campaign'].str.contains('app')) & \n",
    "                    (df_safe['attr_window'] == 'Combined')]\n",
    "\n",
    "games_reg_df = df_safe[(df_safe['marketing_subinitiative'].isin(['Games'])) & \n",
    "                     ~(df_safe['campaign'].str.contains('app')) & \n",
    "                    (df_safe['attr_window'] == 'Combined')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up date col\n",
    "cooking_reg_df['date'] = cooking_reg_df['date'].astype('datetime64[ns]')\n",
    "games_reg_df['date'] = games_reg_df['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group cooking and games reg_dfs to daily spend, impressions + rename cols\n",
    "cooking_daily = cooking_reg_df.groupby('date')[['impressions','spend']].sum().reset_index().rename(columns={'impressions':'ck_impressions',\n",
    "                                                                                       'spend':'ck_spend'})\n",
    "games_daily = games_reg_df.groupby('date')[['impressions','spend']].sum().reset_index().rename(columns={'impressions':'games_impressions',\n",
    "                                                                                       'spend':'games_spend'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge cooking and games info into reg_df that we'll use for regression\n",
    "reg_df = reg_df.merge(cooking_daily, how='left', on='date')\n",
    "reg_df = reg_df.merge(games_daily, how='left', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NA with 0\n",
    "reg_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index as date\n",
    "reg_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_vars = [col for col in reg_df.columns if 'impressions' in col and 'Brand' not in col and 'UNKNOWN' not in col] + \\\n",
    "[col for col in reg_df.columns if 'month_' in col]\n",
    "# [col for col in reg_df.columns if 'weekday_' in col] + \\\n",
    "# [col for col in reg_df.columns if 'core_conversions' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reg_df[indep_vars]\n",
    "y = reg_df[['spg_conversions_all']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### optional: try grouping by week to reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.reset_index(inplace=True)\n",
    "y.reset_index(inplace=True)\n",
    "\n",
    "X['year_week_monday'] = X['date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "y['year_week_monday'] = y['date'].dt.to_period('W').apply(lambda r: r.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.groupby('year_week_monday').agg({'ck_impressions':'sum',\n",
    "                                 'games_impressions':'sum',\n",
    "                                 'impressions_Display - Business As Usual':'sum',\n",
    "                                 'impressions_Display - Content/Audience Development':'sum',\n",
    "                                 'impressions_Display - Engagement':'sum',\n",
    "                                 'impressions_Display - Gifting':'sum',\n",
    "                                 'impressions_Display - One Day Sale':'sum',\n",
    "                                 'impressions_Display - Sale':'sum',\n",
    "                                 'impressions_Display - Testing':'sum',\n",
    "                                 'impressions_Display - X-UNKNOWN-X':'sum',\n",
    "                                 'impressions_Native - Business As Usual':'sum',\n",
    "                                 'impressions_Native - Content/Audience Development':'sum',\n",
    "                                 'impressions_Native - Gifting':'sum',\n",
    "                                 'impressions_Native - One Day Sale':'sum',\n",
    "                                 'impressions_Native - Sale':'sum',\n",
    "                                 'impressions_Other - Business As Usual':'sum',\n",
    "                                 'impressions_Other - Content/Audience Development':'sum',\n",
    "                                 'impressions_Paid Search - Business As Usual':'sum',\n",
    "                                 'impressions_Paid Search - Content/Audience Development':'sum',\n",
    "                                 'impressions_Paid Search - Engagement':'sum',\n",
    "                                 'impressions_Paid Search - Gifting':'sum',\n",
    "                                 'impressions_Paid Search - One Day Sale':'sum',\n",
    "                                 'impressions_Paid Search - Retention':'sum',\n",
    "                                 'impressions_Paid Search - Sale':'sum',\n",
    "                                 'impressions_Social - App-Install':'sum',\n",
    "                                 'impressions_Social - Audience Content':'sum',\n",
    "                                 'impressions_Social - Business As Usual':'sum',\n",
    "                                 'impressions_Social - Content/Audience Development':'sum',\n",
    "                                 'impressions_Social - DR and Content Combined':'sum',\n",
    "                                 'impressions_Social - Gifting':'sum',\n",
    "                                 'impressions_Social - One Day Sale':'sum',\n",
    "                                 'impressions_Social - Sale':'sum',\n",
    "                                 'impressions_Social - X-UNKNOWN-X':'sum',\n",
    "                                 'impressions_Video - Business As Usual':'sum',\n",
    "                                 'impressions_Video - One Day Sale':'sum',\n",
    "                                 'impressions_Video - Sale':'sum',\n",
    "                                 'impressions_X-UNKNOWN-X - Business As Usual':'sum',\n",
    "                                 'impressions_X-UNKNOWN-X - Content/Audience Development':'sum',\n",
    "                                 'impressions_Youtube - Content/Audience Development':'sum',\n",
    "                                 'impressions_Youtube - X-UNKNOWN-X':'sum',\n",
    "                                 'month_April':'max',\n",
    "                                 'month_August':'max',\n",
    "                                 'month_December':'max',\n",
    "                                 'month_February':'max',\n",
    "                                 'month_January':'max',\n",
    "                                 'month_July':'max',\n",
    "                                 'month_June':'max',\n",
    "                                 'month_March':'max',\n",
    "                                 'month_May':'max',\n",
    "                                 'month_November':'max',\n",
    "                                 'month_October':'max',\n",
    "                                 'month_September':'max'\n",
    "                               })\n",
    "\n",
    "y = y.groupby('year_week_monday').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# scaled = scaler.fit_transform(X)\n",
    "\n",
    "# X = pd.DataFrame(data=scaled, columns=X.columns)\n",
    "# X['date'] = reg_df_reg.index.values\n",
    "# X.set_index('date', inplace=True)\n",
    "\n",
    "# y['date'] = reg_df_reg.index.values\n",
    "# y.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "\n",
    "ols_test = sm.OLS(y, X).fit() \n",
    "\n",
    "ols_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_y_pred = ols_test.predict(X)\n",
    "\n",
    "ols_vis = X.copy()\n",
    "ols_vis['y_pred'] = ols_y_pred\n",
    "ols_vis['y_actual'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='spg_convs_predicted'))\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='spg_convs_actual'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Try holding out the last few months__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_s = '2019-01-01'\n",
    "is_e = '2020-12-31'\n",
    "\n",
    "oos_s = '2021-01-01'\n",
    "oos_e = '2021-04-01'\n",
    "\n",
    "X_train = X.loc[is_s:is_e]\n",
    "X_test = X.loc[oos_s:oos_e]\n",
    "\n",
    "y_train = y.loc[is_s:is_e]\n",
    "y_test = y.loc[oos_s:oos_e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "\n",
    "ols = sm.OLS(y_train, X_train).fit() \n",
    "\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# TRAIN\n",
    "######################################\n",
    "\n",
    "train_ols_y_pred = ols.predict(X_train)\n",
    "\n",
    "train_ols_vis = X_train.copy()\n",
    "train_ols_vis['y_pred'] = train_ols_y_pred\n",
    "train_ols_vis['y_actual'] = y_train\n",
    "\n",
    "#####################################\n",
    "# TEST\n",
    "######################################\n",
    "test_ols_y_pred = ols.predict(X_test)\n",
    "\n",
    "test_ols_vis = X_test.copy()\n",
    "test_ols_vis['y_pred'] = test_ols_y_pred\n",
    "test_ols_vis['y_actual'] = y_test\n",
    "\n",
    "######################################\n",
    "# COMBINE\n",
    "######################################\n",
    "\n",
    "ols_vis = pd.concat([train_ols_vis,test_ols_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='spg_conversions_predicted'))\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='spg_conversions_actual'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_vis['all_core_impressions'] = ols_vis[[col for col in ols_vis.columns if 'impressions' in col and 'games' not in col and 'ck_' not in col]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(ols_vis, ['games_impressions','ck_impressions','all_impressions','y_pred','y_actual'], one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Try Stepwise__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "def forward_selected(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    i = 1\n",
    "    while remaining and current_score == best_new_score:\n",
    "        print(f\"Iteration: {i}\")\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "            print(\"New best model found\")\n",
    "            print(formula)\n",
    "        i += 1\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_df = reg_df[is_s:is_e][indep_vars + ['spg_conversions_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_df.columns = stepwise_df.columns.str.replace(' ', '')\n",
    "stepwise_df.columns = stepwise_df.columns.str.replace('-','_')\n",
    "stepwise_df.columns = stepwise_df.columns.str.replace('/','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"spg_conversions_all ~ ck_impressions + games_impressions + impressions_Display_Sale + impressions_Social_BusinessAsUsual + impressions_PaidSearch_Sale + month_June + month_April + impressions_PaidSearch_Gifting + impressions_Display_Gifting + month_May + impressions_Native_Content_AudienceDevelopment + impressions_Social_Gifting + impressions_Social_Content_AudienceDevelopment + impressions_PaidSearch_BusinessAsUsual + impressions_Display_Testing + month_March + month_July + impressions_Social_X_UNKNOWN_X + impressions_Display_BusinessAsUsual + impressions_Display_Content_AudienceDevelopment + 1\"\n",
    "stepwise_model = smf.ols(formula, stepwise_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stepwise_df_test = reg_df[oos_s:oos_e][indep_vars]\n",
    "\n",
    "stepwise_df_test.columns = stepwise_df_test.columns.str.replace(' ', '')\n",
    "stepwise_df_test.columns = stepwise_df_test.columns.str.replace('-','_')\n",
    "stepwise_df_test.columns = stepwise_df_test.columns.str.replace('/','_')\n",
    "\n",
    "stepwise_df_train = reg_df[is_s:is_e][indep_vars]\n",
    "\n",
    "stepwise_df_train.columns = stepwise_df_train.columns.str.replace(' ', '')\n",
    "stepwise_df_train.columns = stepwise_df_train.columns.str.replace('-','_')\n",
    "stepwise_df_train.columns = stepwise_df_train.columns.str.replace('/','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# TRAIN\n",
    "######################################\n",
    "\n",
    "stepwise_train_y_pred = stepwise_model.predict(stepwise_df_train)\n",
    "stepwise_df_train['y_pred'] = stepwise_train_y_pred\n",
    "stepwise_df_train['y_actual'] = reg_df[is_s:is_e]['spg_conversions_all']\n",
    "\n",
    "#####################################\n",
    "# TEST\n",
    "######################################\n",
    "stepwise_test_y_pred = stepwise_model.predict(stepwise_df_test)\n",
    "stepwise_df_test['y_pred'] = stepwise_test_y_pred\n",
    "stepwise_df_test['y_actual'] = reg_df[oos_s:oos_e]['spg_conversions_all']\n",
    "\n",
    "######################################\n",
    "# COMBINE\n",
    "######################################\n",
    "\n",
    "stepwise_vis = pd.concat([stepwise_df_train,stepwise_df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(stepwise_vis, ['y_pred','y_actual'], one_plot=True, scaled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Capture basic info on cross-sell (Cooking Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Identify cross-sell patterns (CK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Look at volumes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_init_vol = df_core.groupby(['marketing_initiative'])['impressions', 'ck_conversions'].sum().sort_values('ck_conversions', ascending=False)\n",
    "mkt_init_vol.reset_index(inplace=True)\n",
    "mkt_init_vol['impression_weights'] = mkt_init_vol['impressions'] / mkt_init_vol['ck_conversions']\n",
    "mkt_init_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_init_vol.sort_values('impression_weights', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sale, Content/Audience Dev, and BAU make up the vast majority of CK cross sells. However, this is mostly because of sheer impression volume. The most efficient tactics are those with the lowest impression weights - Testing, Gifting, Audience Content, Content/Audience Dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_vol = df_core.groupby(['channel'])['impressions','ck_conversions'].sum().sort_values('ck_conversions', ascending=False)\n",
    "channel_vol.reset_index(inplace=True)\n",
    "channel_vol['impression_weights'] = channel_vol['impressions'] / channel_vol['ck_conversions']\n",
    "channel_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_vol.sort_values('impression_weights', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display, Native and Social drove the most cross-sells. But Paid Search drove the most efficient cross-sells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mkt_vol = df_core.groupby('channel_mkt_init')['impressions','ck_conversions'].sum().sort_values('ck_conversions',ascending=False)\n",
    "channel_mkt_vol.reset_index(inplace=True)\n",
    "channel_mkt_vol['impression_weights'] = channel_mkt_vol['impressions'] / channel_mkt_vol['ck_conversions']\n",
    "channel_mkt_vol.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mkt_vol.sort_values('impression_weights', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various Paid Search and Display tactics drove the most efficient cross-sell results. Meanwhile, Display Social and Native (Sale and Content/Audience Dev) drove the highest volume of cross-sells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Look at correlations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create monthly view\n",
    "df_core_monthly = df_core.groupby(['year_month_cal','channel_mkt_init'])[['clicks','impressions','games_conversions','ck_conversions']].sum().reset_index()\n",
    "\n",
    "#pivot to only have only one row per month\n",
    "df_core_monthly = df_core_monthly.pivot(index='year_month_cal', columns='channel_mkt_init', values=['clicks','impressions','games_conversions','ck_conversions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten index\n",
    "df_core_monthly.columns = df_core_monthly.columns.to_flat_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create one aggregate ck starts column for simpler correlations\n",
    "df_core_monthly['ck_conversions_all'] = df_core_monthly[[col for col in df_core_monthly.columns if 'ck_conversions' in col]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with just impressions and ck conversions\n",
    "ck_imps_monthly = df_core_monthly[[col for col in df_core_monthly.columns if 'impressions' in col] + ['ck_conversions_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nans with 0 because it means there were no impressions in that period\n",
    "ck_imps_monthly.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get correlations between ck starts and impression volumes\n",
    "ck_convs_imps_corr = ck_imps_monthly.corrwith(ck_imps_monthly['ck_conversions_all']).to_frame().rename(columns={0:'corr_with_ck_conv'}).reset_index()\n",
    "\n",
    "#sort the frame\n",
    "ck_convs_imps_corr.sort_values('corr_with_ck_conv', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_convs_imps_corr.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above correlation chart, it seems that __sales__ have the strongest relationship with cross-sell starts. Major channels such as Paid Search, Display, Native, and Social show the highest correlation. That said, the highest correlation by far is Paid Search - Sale; other channels have modest relationships with CK conversions (~.50 or less)\n",
    "\n",
    "This preliminary analysis would indicate that sale-based Core media does the best job attracting Cooking starts.\n",
    "\n",
    "Social - Audience/Content also seems to do a fairly good job generating CK starts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Try a Regression (CK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cols to try: \n",
    "* campaign_objective\n",
    "* marketing_initiative\n",
    "* marketing_segment\n",
    "* channel\n",
    "* platform\n",
    "* impressions\n",
    "* core_conversions\n",
    "* month dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce number of cols \n",
    "df_reg = df_core[(df_core['channel'].isin(['Display','Native','Social','Paid Search'])) & \n",
    "                (df_core['marketing_initiative'].isin(['Sale','Content/Audience Development','Business As Usual','One Day Sale']))].groupby(['date','channel','marketing_initiative'])[['impressions','core_conversions','ck_conversions']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.groupby(['date'])[['impressions','core_conversions','ck_conversions']].sum().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create month and weekday cols for dummies\n",
    "df_reg['weekday'] = df_reg['date'].apply(lambda x: x.strftime('%A'))\n",
    "df_reg['month'] = df_reg['date'].dt.month_name()\n",
    "\n",
    "#create a merge dummies \n",
    "df_reg = pd.concat([df_reg, \n",
    "                  pd.get_dummies(df_reg['channel'], prefix='channel'),\n",
    "                 pd.get_dummies(df_reg['marketing_initiative'], prefix='mkt_init'), \n",
    "               pd.get_dummies(df_reg['weekday'], prefix='weekday'), \n",
    "               pd.get_dummies(df_reg['month'], prefix='month')], axis=1)\n",
    "\n",
    "#drop old cols and set index to date\n",
    "df_reg.drop(['channel','marketing_initiative','weekday','month'], axis=1, inplace=True)\n",
    "df_reg.set_index('date', inplace=True)\n",
    "\n",
    "# #add some holiday dummies for cooking \n",
    "# df_reg['xmas'] = 0\n",
    "# df_reg.loc['2020-12-20':'2020-12-25', 'xmas'] = 1\n",
    "\n",
    "# df_reg['thanksgiving'] = 0\n",
    "# df_reg.loc['2020-11-22':'2020-11-25', 'thanksgiving'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.groupby('date').agg({'impressions': 'sum',\n",
    "                            'core_conversions':'sum',\n",
    "                            'ck_conversions':'sum',\n",
    "                            'channel_Display':'max',\n",
    "                             'channel_Native':'max',\n",
    "                             'channel_Paid Search':'max',\n",
    "                             'channel_Social':'max',\n",
    "                             'mkt_init_Business As Usual':'max',\n",
    "                             'mkt_init_Content/Audience Development':'max',\n",
    "                             'mkt_init_One Day Sale':'max',\n",
    "                             'mkt_init_Sale':'max',\n",
    "                             'month_April':'max',\n",
    "                             'month_August':'max',\n",
    "                             'month_December':'max',\n",
    "                             'month_February':'max',\n",
    "                             'month_January':'max',\n",
    "                             'month_July':'max',\n",
    "                             'month_June':'max',\n",
    "                             'month_March':'max',\n",
    "                             'month_May':'max',\n",
    "                             'month_November':'max',\n",
    "                             'month_October':'max',\n",
    "                             'month_September':'max',\n",
    "                             'weekday_Friday':'max',\n",
    "                             'weekday_Monday':'max',\n",
    "                             'weekday_Saturday':'max',\n",
    "                             'weekday_Sunday':'max',\n",
    "                             'weekday_Thursday':'max',\n",
    "                             'weekday_Tuesday':'max',\n",
    "                             'weekday_Wednesday':'max'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reg.drop('ck_conversions', axis=1)\n",
    "y = df_reg[['ck_conversions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(data=scaled, columns=X.columns)\n",
    "X['date'] = df_reg.index.values\n",
    "X.set_index('date', inplace=True)\n",
    "\n",
    "y['date'] = df_reg.index.values\n",
    "y.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "\n",
    "ols_test = sm.OLS(y, X).fit() \n",
    "\n",
    "ols_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_y_pred = ols_test.predict(X)\n",
    "\n",
    "ols_vis = X.copy()\n",
    "ols_vis['y_pred'] = ols_y_pred\n",
    "ols_vis['y_actual'] = y\n",
    "\n",
    "ols_daily = ols_vis.reset_index().groupby('date').sum()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ols_daily.index, y=ols_daily['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_predicted'))\n",
    "fig.add_trace(go.Scatter(x=ols_daily.index, y=ols_daily['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_actual'))\n",
    "fig.add_trace(go.Scatter(x=ols_daily.index, y=ols_daily['impressions'],\n",
    "                    mode='lines',\n",
    "                    name='total_core_impressions'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scaled version of residuals plot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scaler = MinMaxScaler()\n",
    "plot_scaled = plot_scaler.fit_transform(ols_daily)\n",
    "\n",
    "\n",
    "plot_daily = pd.DataFrame(data=plot_scaled, columns=ols_daily.columns)\n",
    "plot_daily['date'] = ols_daily.index.values\n",
    "plot_daily.set_index('date', inplace=True)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_predicted'))\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_actual'))\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['impressions'],\n",
    "                    mode='lines',\n",
    "                    name='total_core_impressions'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial pass was garbage. There are likely several reasons for this, but first and foremost is that we have too many independent variables, too few observations which include those independent variables, and independent variables that have little to no relationship with our dependent (in this case, Cooking starts). \n",
    "\n",
    "To refine the regression approach we need to do more EDA to understand which channels and tactics have the most explanatory power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE: CK conversions drop to near zero in May through July, and also have major spikes around Thanksgiving and Xmas. Cooking media went dark in May through July, and also has the heaviest spend around the aforementioned holidays. The absence of Cooking starts during the dark period and the holiday spikes could indicate that these Cooking \"cross sell\" starts are really being driven by Cooking media, and the audiences also happened to be served Core ads which greedily picked up the credit. Need to explore this further - very important caveat to this analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Critical open question:__\n",
    "* How do we remove the influence of Cooking/Games paid media that ran concurrently with Core paid media?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible solution could be to __only include click-through cross-sell conversions__ in this analysis. That way we can be a little more sure that it was, in fact, the Core ad that generated the CK or Games conversion. This would be a more conservative approach, but would mitigate the risk that we go on to calculate a blended CPO based on misattributed viewthrough conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try two model improvements, separately: \n",
    "\n",
    "#### A) just look at click-thru conversions\n",
    "#### B) add in CK spend/impressions to regression and see how it correlates / comes into the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_daily = df[(df['marketing_subinitiative'] == 'Cooking') & \n",
    "  (df['attr_window'] == 'Media Reported') & \n",
    "  (df['marketing_initiative'] != 'App Download') & \n",
    "  ~(df['campaign'].str.contains('app'))]\n",
    "\n",
    "ck_daily['date'] = ck_daily['date'].astype('datetime64[ns]')\n",
    "\n",
    "ck_daily = ck_daily.groupby('date').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_daily.rename(columns = {'impressions':'ck_impressions',\n",
    "                          'spend':'ck_spend'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.reset_index(inplace=True)\n",
    "df_reg['date'] = df_reg['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.merge(ck_daily[['date','ck_impressions']], how='left', on='date').fillna(0)\n",
    "df_reg.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reg.drop('ck_conversions', axis=1)\n",
    "y = df_reg[['ck_conversions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(data=scaled, columns=X.columns)\n",
    "X['date'] = df_reg.index.values\n",
    "X.set_index('date', inplace=True)\n",
    "\n",
    "y['date'] = df_reg.index.values\n",
    "y.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "\n",
    "ols_test = sm.OLS(y, X).fit() \n",
    "\n",
    "ols_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scaler = MinMaxScaler()\n",
    "plot_scaled = plot_scaler.fit_transform(ols_daily)\n",
    "\n",
    "\n",
    "plot_daily = pd.DataFrame(data=plot_scaled, columns=ols_daily.columns)\n",
    "plot_daily['date'] = ols_daily.index.values\n",
    "plot_daily.set_index('date', inplace=True)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_predicted'))\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_actual'))\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['impressions'],\n",
    "                    mode='lines',\n",
    "                    name='total_core_impressions'))\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['ck_impressions'],\n",
    "                    mode='lines',\n",
    "                    name='ck_impressions'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data stuff\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "#regression stuff\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#graph stuff\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objects as go\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "#import functions from other file that we want\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>g</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age sex  store\n",
       "0   a   e      1\n",
       "1   b   f      2\n",
       "2   c   g      3\n",
       "3   a   f      3\n",
       "4   b   e      2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample,shuffle\n",
    "#create a dataframe\n",
    "df = {'age':['a','b','c','a','b'],'sex':['e','f','g','f','e'],'store':[1,2,3,3,2]}\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I: CROSS-SELL DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Read in PMD Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When running back to 2016 or so this costs 90GB, running back through beginning of 2020 costs about 25GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''\n",
    "SELECT \n",
    "     account\n",
    "    , attr_window\n",
    "    , campaign\n",
    "    , _match\n",
    "    , campaign_objective\n",
    "    , date\n",
    "    , marketing_initiative\n",
    "    , marketing_segment\n",
    "    , marketing_subinitiative\n",
    "    , channel\n",
    "    , platform\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then spend else 0 end) spend\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then clicks else 0 end) clicks\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then impressions else 0 end) impressions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Core' then conversions else null end) digi_ada_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Crosswords' then conversions else null end) games_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'EDU' then conversions else null end) edu_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Home Delivery' then conversions else null end) hd_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'CK' then conversions else null end) ck_conversions     \n",
    "    , sum(case\n",
    "            when sor_prod = 'Core All (Core, HD, EDU)' then conversions else null end) core_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'All (Core All, NPV)' then conversions else null end) all_conversions\n",
    "FROM `nyt-mkt-prd.paid_media_data.placement_daily_vw`\n",
    "WHERE date >= '2016-01-01' and attr_window in('Combined')\n",
    "group by 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\n",
    "order by date, campaign, _match\n",
    "\n",
    "'''\n",
    "\n",
    "start_time = time.time() \n",
    "\n",
    "df = pd.read_gbq(q,\n",
    "                 project_id ='nyt-bigquery-beta-workspace',\n",
    "                 dialect='standard',\n",
    "                 verbose=False)\n",
    "\n",
    "print(f'time took: {str(round(time.time() - start_time, 2))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on use of attribution window:\n",
    "* Use the same attr_window for each channel\n",
    "* Media team right now uses _combined_ attr_window, which is mostly Media Reported but some quirks\n",
    "* For this analysis, we should use:\n",
    "    * __Combined__ and __Media Reported - Click Thru__\n",
    "* Do one version that looks only at Media Reported click thru and one version that looks at combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "the below is no longer needed - I had terrible wifi in Puerto Rico so had to chunk the data pull\n",
    "'''\n",
    "increment=200000\n",
    "chunks=list(range(0, 1838251, increment))\n",
    "\n",
    "chunks[-1]+=increment \n",
    "intervals=[[chunks[i-1], chunks[i]+1] for i, e in enumerate(chunks) if i > 0]\n",
    "\n",
    "query_str='''\n",
    "select * from `nyt-bigquery-beta-workspace.lucas_data.pmd_data_jan_20_to_apr_21`\n",
    "order by 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21 limit {end} offset {start}\n",
    "'''\n",
    "\n",
    "df = pd.DataFrame() \n",
    "\n",
    "for start, end in intervals:  \n",
    "    q = query_str.format(start=start, end=end)\n",
    "    print(f\"running query: {q}\")\n",
    "    start_time = time.time()  \n",
    "    temp_df = pd.read_gbq(q,\n",
    "                 project_id ='nyt-bigquery-beta-workspace',\n",
    "                 dialect='standard',\n",
    "                 verbose=False)\n",
    "    print(f'time took: {str(round(time.time() - start_time, 2))}')\n",
    "    df = pd.concat([df, temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep a copy of the original just to be safe\n",
    "df_safe = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_safe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idk why there's duplicates but there are... so drop them\n",
    "print(f\"Rows before duplicates removed: {df.shape[0]}\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Rows after duplicates removed: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('all_pmd_data_jan_20_to_apr_21.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKPOINT: read in data from CSV here if needed. Begin to limit data to just Core media activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['marketing_subinitiative'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some Twigeo campaigns don't get recognized as Games campaigns in PMD, manually correct those\n",
    "df.loc[(df['marketing_subinitiative'] == 'X-UNKNOWN-X') & \n",
    "       (\n",
    "          (df['campaign'].str.contains('game')) | \n",
    "          (df['campaign'].str.contains('xwd')) | \n",
    "          (df['campaign'].str.contains('cross'))\n",
    "       ), 'marketing_subinitiative'] = 'Games (former: Crosswords)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add columns for easier grouping (quarter, month, week) + analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create date-based aggregation columns for easier grouping\n",
    "df['year_month_cal'] = df['date'].dt.to_period('M').apply(lambda r: r.start_time)\n",
    "df['year_week_monday'] = df['date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "df['year_quarter'] = df['date'].dt.to_period('Q').apply(lambda r: r.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a combined spg_conversions column from games and ck\n",
    "df['spg_conversions'] = df['games_conversions'] + df['ck_conversions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a composite channel-marketing-initiative column for a pd.melt\n",
    "df['channel_mkt_init'] = df['channel'] + \" - \" + df['marketing_initiative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE: we are going to remove brand, app install, retention data because it is not acquisition-focused__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['marketing_initiative'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['marketing_initiative'].isin(['Brand','Branding','Retention','App Download'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DF of Core-Only campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['marketing_subinitiative'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit to Core campaigns \n",
    "df_core = df[df['marketing_subinitiative'].isin(['Core','CORE Business', 'Home Delivery','EDU'])]\n",
    "\n",
    "#remove mobile partners - conversion data is unreliable in PMD\n",
    "df_core = df_core[~(df_core['account'].str.contains('Twigeo')) & \n",
    "                 ~(df_core['account'] == 'The New York Times App')]\n",
    "\n",
    "#remove app install and app-based campaigns so we focus only on web\n",
    "df_core['campaign'] = df_core['campaign'].str.lower()\n",
    "df_core = df_core[~df_core['campaign'].str.contains('app')]\n",
    "\n",
    "\n",
    "#limit attribution window to media-reported. We may want to reexamine this analysis in the future using other windows\n",
    "#such as 7d-all or 1d-all\n",
    "df_core = df_core[df_core['attr_window'] == 'Combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__create a daily core dataframe__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create daily view of impressions, core starts, spg starts\n",
    "df_core_daily = df_core.groupby(['year_quarter','year_month_cal','year_week_monday','date'])['spend','impressions', 'clicks', 'core_conversions','spg_conversions',\n",
    "                                         'ck_conversions','games_conversions'].sum().reset_index()\n",
    "\n",
    "#rename cols\n",
    "df_core_daily.rename(columns = {'spend':'core_spend', \n",
    "                           'impressions':'core_impressions', \n",
    "                                'clicks':'core_clicks', \n",
    "                             'spg_conversions':'core_spg_conversions', \n",
    "                             'ck_conversions':'core_ck_conversions',\n",
    "                             'games_conversions':'core_games_conversions'},\n",
    "                   inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DF of SPG-Only Campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spg = df[(df['marketing_subinitiative'].isin(['Cooking','Games'])) & \n",
    "  ~(df['campaign'].str.contains('app'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spg[['ck_conversions','games_conversions']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__create a daily SPG dataframe__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spg_daily = df_spg.groupby(['year_quarter','year_month_cal','year_week_monday',\n",
    "                               'date', 'marketing_subinitiative'])['spend','impressions','spg_conversions'].sum().reset_index()\n",
    "\n",
    "df_spg_daily = df_spg_daily.pivot(index=['year_quarter','year_month_cal','year_week_monday','date'], \n",
    "                                  columns='marketing_subinitiative', \n",
    "                                  values=['spend','impressions', 'spg_conversions']).reset_index()\n",
    "\n",
    "df_spg_daily.columns = ['_'.join(col).strip() for col in df_spg_daily.columns.values]\n",
    "df_spg_daily.rename(columns = {'spend_Cooking':'ck_spend',\n",
    "                               'spend_Games':'games_spend',\n",
    "                               'impressions_Cooking':'ck_impressions',\n",
    "                               'impressions_Games':'games_impressions',\n",
    "                               'spg_conversions_Cooking':'ck_ck_conversions',\n",
    "                               'spg_conversions_Games':'games_games_conversions',\n",
    "                               'year_quarter_':'year_quarter',\n",
    "                               'year_month_cal_':'year_month_cal',\n",
    "                               'year_week_monday_':'year_week_monday',\n",
    "                               'date_':'date'\n",
    "                              },\n",
    "                   inplace=True)\n",
    "\n",
    "df_spg_daily['spg_spend'] = df_spg_daily['ck_spend'] + df_spg_daily['games_spend']\n",
    "df_spg_daily['spg_impressions'] = df_spg_daily['ck_impressions'] + df_spg_daily['games_impressions']\n",
    "df_spg_daily['spg_spg_conversions'] = df_spg_daily['ck_ck_conversions'] + df_spg_daily['games_games_conversions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Core and SPG DFs to get one daily view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df_core_daily.merge(df_spg_daily, how='left', on=['year_quarter','year_month_cal','year_week_monday','date'])\n",
    "df_daily['date'] = df_daily.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Top level analysis on Core-to-SPG cross sell (Core campaigns driving CK or Games starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#understand overall impact 1 Jan 2019 - 1 May 2021\n",
    "df_core[['core_conversions','games_conversions','ck_conversions']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Since January 2019, web-based Core media (note: this analysis excludes app-based media) has generated 1.66M starts. It has also recorded 32.9k Games starts and 59.7k Cooking starts which have never been recognized!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most recent 5 year LTVs I found for Cooking and Games are as follows: \n",
    "* Cooking: $124\n",
    "\n",
    "* Games: $97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sums = df_core[['core_conversions','games_conversions','ck_conversions']].sum().to_frame()\n",
    "games_val = start_sums.loc['games_conversions'][0] * 97\n",
    "ck_val = start_sums.loc['ck_conversions'][0] * 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Games added value: ${:>15,.2f}'.format(games_val))\n",
    "print('CK added value: ${:>18,.2f}'.format(ck_val))\n",
    "print('Combined value: ${:>18,.2f}'.format(games_val + ck_val, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means upon initial glance, web-based campaigns since Jan 2019 have generated over $10.6M in unrecognized value based on media reporting. \n",
    "\n",
    "However, this is an incomplete picture because we don't know: \n",
    "<ol>\n",
    "    <li> to what extent the core campaigns actually drove these conversions (are they incremental?) </li>\n",
    "    <li> if these starts were already counted as part of separate CK or Games campaigns (are they deduplicated?) </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Quarterly, Monthly, Weekly, Daily views of impressions, core starts, SPG starts to understand if there is a consistent relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get lists of columns for product-specific analysis\n",
    "core_to_ck_cols = [col for col in df_daily.columns if ('core' in col and 'games' not in col and 'spg' not in col) or 'ck' in col]\n",
    "core_to_games_cols = [col for col in df_daily.columns if ('core' in col and 'ck' not in col and 'spg' not in col) or 'games' in col]\n",
    "core_to_spg_cols = [col for col in df_daily.columns if ('core' in col and 'games' not in col and 'ck' not in col) or 'spg' in col]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quarterly, Monthly, Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by quarter, month, week\n",
    "df_qtr = df_daily.groupby('year_quarter').sum()\n",
    "df_monthly = df_daily.groupby('year_month_cal').sum()\n",
    "df_weekly = df_daily.groupby('year_week_monday').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr_matrix(df_weekly, core_to_games_cols, start='2019-01-01', end='2020-03-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(df_weekly, ['games_impressions','games_games_conversions', 'games_spend'], one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(df_weekly['2020-04-01':], core_to_games_cols, one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly.corrwith(df_weekly['core_spg_conversions']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=5, cols=2, \n",
    "                   subplot_titles = [item + f\": {round(df_core_qtr.corrwith(df_core_qtr['core_spg_conversions']).sort_values(ascending=False)[item], 2)}\" for item in df_core_qtr.corrwith(df_core_qtr['core_spg_conversions']).sort_values(ascending=False).index])\n",
    "\n",
    "i = 0\n",
    "row_list = [1,1,2,2,3,3,4,4,5,5]\n",
    "x = df_core_qtr['core_spg_conversions']\n",
    "\n",
    "for col in df_core_qtr.corrwith(df_core_qtr['core_spg_conversions']).sort_values(ascending=False).index:\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=df_core_qtr[col],\n",
    "            mode='markers'\n",
    "        ),\n",
    "        row=row_list[i], col= (i%2) + 1\n",
    "    )\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "fig.update_layout(height=2000, width=800, title_text=\"Core-driven SPG starts scatterplots\", showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create monthly view of impressions, core starts, spg starts\n",
    "df_core_mnth = df_core.groupby('year_month_cal')['spend','impressions', 'clicks', 'core_conversions','spg_conversions',\n",
    "                                         'ck_conversions','games_conversions'].sum()\n",
    "\n",
    "#rename cols\n",
    "df_core_mnth.rename(columns = {'spend':'core_spend', \n",
    "                           'impressions':'core_impressions',\n",
    "                               'clicks':'core_clicks',\n",
    "                             'spg_conversions':'core_spg_conversions', \n",
    "                             'ck_conversions':'core_ck_conversions',\n",
    "                             'games_conversions':'core_games_conversions'},\n",
    "                   inplace=True)\n",
    "\n",
    "#add in SPG impression, conversion, data\n",
    "df_spg_mnth = df_spg.groupby('year_month_cal')['spend','impressions','spg_conversions'].sum()\n",
    "df_spg_mnth.rename(columns = {'spend':'spg_spend',\n",
    "                        'impressions':'spg_impressions', \n",
    "                            'spg_conversions':'spg_spg_conversions'},\n",
    "                  inplace=True)\n",
    "\n",
    "df_core_mnth = df_core_mnth.merge(df_spg_mnth, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr_matrix(df_core_mnth, var_list=df_core_mnth.columns, start=df_core_mnth.index.min(), end=df_core_mnth.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(df_core_mnth, df_core_mnth.columns, one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=5, cols=2, \n",
    "                   subplot_titles = [item + f\": {round(df_core_mnth.corrwith(df_core_mnth['core_spg_conversions']).sort_values(ascending=False)[item], 2)}\" for item in df_core_mnth.corrwith(df_core_mnth['core_spg_conversions']).sort_values(ascending=False).index])\n",
    "\n",
    "i = 0\n",
    "row_list = [1,1,2,2,3,3,4,4,5,5]\n",
    "x = df_core_mnth['core_spg_conversions']\n",
    "\n",
    "for col in df_core_mnth.corrwith(df_core_mnth['core_spg_conversions']).sort_values(ascending=False).index:\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=df_core_mnth[col],\n",
    "            mode='markers'\n",
    "        ),\n",
    "        row=row_list[i], col= (i%2) + 1\n",
    "    )\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "fig.update_layout(height=2000, width=800, title_text=\"Core-driven SPG starts scatterplots\", showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create monthly view of impressions, core starts, spg starts\n",
    "df_core_wk = df_core.groupby('year_week_monday')['spend','impressions', 'clicks', 'core_conversions','spg_conversions',\n",
    "                                         'ck_conversions','games_conversions'].sum()\n",
    "\n",
    "#rename cols\n",
    "df_core_wk.rename(columns = {'spend':'core_spend', \n",
    "                           'impressions':'core_impressions',\n",
    "                             'clicks':'core_clicks',\n",
    "                             'spg_conversions':'core_spg_conversions', \n",
    "                             'ck_conversions':'core_ck_conversions',\n",
    "                             'games_conversions':'core_games_conversions'},\n",
    "                   inplace=True)\n",
    "\n",
    "#add in SPG impression, conversion, data\n",
    "df_spg_wk = df_spg.groupby('year_week_monday')['spend','impressions','spg_conversions'].sum()\n",
    "df_spg_wk.rename(columns = {'spend':'spg_spend',\n",
    "                        'impressions':'spg_impressions', \n",
    "                            'spg_conversions':'spg_spg_conversions'},\n",
    "                  inplace=True)\n",
    "\n",
    "df_core_wk = df_core_wk.merge(df_spg_wk, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr_matrix(df_core_wk, var_list=df_core_wk.columns, start=df_core_wk.index.min(), end=df_core_wk.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(df_core_wk, df_core_wk.columns, one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=5, cols=2, \n",
    "                   subplot_titles = [item + f\": {round(df_core_wk.corrwith(df_core_wk['core_spg_conversions']).sort_values(ascending=False)[item], 2)}\" for item in df_core_wk.corrwith(df_core_wk['core_spg_conversions']).sort_values(ascending=False).index])\n",
    "\n",
    "i = 0\n",
    "row_list = [1,1,2,2,3,3,4,4,5,5]\n",
    "x = df_core_wk['core_spg_conversions']\n",
    "\n",
    "for col in df_core_wk.corrwith(df_core_wk['core_spg_conversions']).sort_values(ascending=False).index:\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=df_core_wk[col],\n",
    "            mode='markers'\n",
    "        ),\n",
    "        row=row_list[i], col= (i%2) + 1\n",
    "    )\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "fig.update_layout(height=2000, width=800, title_text=\"Core-driven SPG starts scatterplots\", showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create monthly view of impressions, core starts, spg starts\n",
    "df_core_daily = df_core.groupby('date')['spend','impressions', 'clicks', 'core_conversions','spg_conversions',\n",
    "                                         'ck_conversions','games_conversions'].sum()\n",
    "\n",
    "#rename cols\n",
    "df_core_daily.rename(columns = {'spend':'core_spend', \n",
    "                           'impressions':'core_impressions', \n",
    "                                'clicks':'core_clicks', \n",
    "                             'spg_conversions':'core_spg_conversions', \n",
    "                             'ck_conversions':'core_ck_conversions',\n",
    "                             'games_conversions':'core_games_conversions'},\n",
    "                   inplace=True)\n",
    "\n",
    "#add in SPG impression, conversion, data\n",
    "df_spg_daily = df_spg.groupby('date')['spend','impressions','spg_conversions'].sum()\n",
    "df_spg_daily.rename(columns = {'spend':'spg_spend',\n",
    "                        'impressions':'spg_impressions', \n",
    "                            'spg_conversions':'spg_spg_conversions'},\n",
    "                  inplace=True)\n",
    "\n",
    "df_core_daily = df_core_daily.merge(df_spg_daily, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr_matrix(df_core_daily, var_list=df_core_daily.columns, start=df_core_daily.index.min(), end=df_core_daily.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(df_core_daily, df_core_daily.columns, one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=5, cols=2, \n",
    "                   subplot_titles = [item + f\": {round(df_core_daily.corrwith(df_core_daily['core_spg_conversions']).sort_values(ascending=False)[item], 2)}\" for item in df_core_daily.corrwith(df_core_daily['core_spg_conversions']).sort_values(ascending=False).index])\n",
    "\n",
    "i = 0\n",
    "row_list = [1,1,2,2,3,3,4,4,5,5]\n",
    "x = df_core_daily['core_spg_conversions']\n",
    "\n",
    "for col in df_core_daily.corrwith(df_core_daily['core_spg_conversions']).sort_values(ascending=False).index:\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=df_core_daily[col],\n",
    "            mode='markers'\n",
    "        ),\n",
    "        row=row_list[i], col= (i%2) + 1\n",
    "    )\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "fig.update_layout(height=2000, width=800, title_text=\"Core-driven SPG starts scatterplots\", showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. look for more granular correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correls_df = df_core.groupby(['year_month_cal','year_week_monday','date','channel_mkt_init']).sum().reset_index()\n",
    "correls_df = correls_df.pivot(index='date', columns='channel_mkt_init', values=['clicks','impressions','games_conversions','ck_conversions', 'spg_conversions'])\n",
    "\n",
    "correls_df.columns = ['_'.join(col).strip() for col in correls_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correls_df.columns = correls_df.columns.str.replace(' - ','_').str.replace('/','').str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core['channel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correls_df[[col for col in correls_df.columns if 'Native' in col and 'ck_conversions' not in col and 'games_conversions' not in col]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(correls_df, ['clicks_Native_Sale','impressions_Native_Sale','spg_conversions_Native_Sale'], one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Try regression - with all data and impression volumes across channel_mkt_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__construct impressions, clicks, and starts columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = df_core.groupby(['date','channel_mkt_init'])['clicks','impressions','spend','core_conversions','spg_conversions'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = reg_df.pivot(index='date', columns='channel_mkt_init', values=['clicks','impressions','spend','core_conversions','spg_conversions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.columns = reg_df.columns = ['_'.join(col).strip() for col in reg_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.reset_index(inplace=True)\n",
    "reg_df['date'] = reg_df['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df['spg_conversions_all'] = reg_df[[col for col in reg_df.columns if 'spg_conversions' in col]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create month and weekday cols for dummies\n",
    "reg_df['weekday'] = reg_df['date'].apply(lambda x: x.strftime('%A'))\n",
    "reg_df['month'] = reg_df['date'].dt.month_name()\n",
    "\n",
    "#create a merge dummies \n",
    "reg_df = pd.concat([reg_df, \n",
    "               pd.get_dummies(reg_df['weekday'], prefix='weekday'), \n",
    "               pd.get_dummies(reg_df['month'], prefix='month')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__add spg impressions, spend information__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create reg_dfs from main data pull with only cooking and games data\n",
    "\n",
    "cooking_reg_df = df[(df['marketing_subinitiative'].isin(['Cooking'])) & \n",
    "                     ~(df['campaign'].str.contains('app')) & \n",
    "                    (df['attr_window'] == 'Combined')]\n",
    "\n",
    "games_reg_df = df[(df['marketing_subinitiative'].isin(['Games'])) & \n",
    "                     ~(df['campaign'].str.contains('app')) & \n",
    "                    (df['attr_window'] == 'Combined')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up date col\n",
    "cooking_reg_df['date'] = cooking_reg_df['date'].astype('datetime64[ns]')\n",
    "games_reg_df['date'] = games_reg_df['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group cooking and games reg_dfs to daily spend, impressions + rename cols\n",
    "cooking_daily = cooking_reg_df.groupby('date')[['impressions','spend']].sum().reset_index().rename(columns={'impressions':'ck_impressions',\n",
    "                                                                                       'spend':'ck_spend'})\n",
    "games_daily = games_reg_df.groupby('date')[['impressions','spend']].sum().reset_index().rename(columns={'impressions':'games_impressions',\n",
    "                                                                                       'spend':'games_spend'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge cooking and games info into reg_df that we'll use for regression\n",
    "reg_df = reg_df.merge(cooking_daily, how='left', on='date')\n",
    "reg_df = reg_df.merge(games_daily, how='left', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NA with 0\n",
    "reg_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index as date\n",
    "reg_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_vars = [col for col in reg_df.columns if 'impressions' in col and 'Brand' not in col and 'UNKNOWN' not in col] + \\\n",
    "[col for col in reg_df.columns if 'month_' in col]\n",
    "# [col for col in reg_df.columns if 'weekday_' in col] + \\\n",
    "# [col for col in reg_df.columns if 'core_conversions' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reg_df[indep_vars]\n",
    "y = reg_df[['spg_conversions_all']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### optional: try grouping by week to reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.reset_index(inplace=True)\n",
    "# y.reset_index(inplace=True)\n",
    "\n",
    "# X['year_week_monday'] = X['date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "# y['year_week_monday'] = y['date'].dt.to_period('W').apply(lambda r: r.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.groupby('year_week_monday').agg({'ck_impressions':'sum',\n",
    "#                                  'games_impressions':'sum',\n",
    "#                                  'impressions_Display - Business As Usual':'sum',\n",
    "#                                  'impressions_Display - Content/Audience Development':'sum',\n",
    "#                                  'impressions_Display - Engagement':'sum',\n",
    "#                                  'impressions_Display - Gifting':'sum',\n",
    "#                                  'impressions_Display - One Day Sale':'sum',\n",
    "#                                  'impressions_Display - Sale':'sum',\n",
    "#                                  'impressions_Display - Testing':'sum',\n",
    "#                                  'impressions_Display - X-UNKNOWN-X':'sum',\n",
    "#                                  'impressions_Native - Business As Usual':'sum',\n",
    "#                                  'impressions_Native - Content/Audience Development':'sum',\n",
    "#                                  'impressions_Native - Gifting':'sum',\n",
    "#                                  'impressions_Native - One Day Sale':'sum',\n",
    "#                                  'impressions_Native - Sale':'sum',\n",
    "#                                  'impressions_Other - Business As Usual':'sum',\n",
    "#                                  'impressions_Other - Content/Audience Development':'sum',\n",
    "#                                  'impressions_Paid Search - Business As Usual':'sum',\n",
    "#                                  'impressions_Paid Search - Content/Audience Development':'sum',\n",
    "#                                  'impressions_Paid Search - Engagement':'sum',\n",
    "#                                  'impressions_Paid Search - Gifting':'sum',\n",
    "#                                  'impressions_Paid Search - One Day Sale':'sum',\n",
    "#                                  'impressions_Paid Search - Retention':'sum',\n",
    "#                                  'impressions_Paid Search - Sale':'sum',\n",
    "#                                  'impressions_Social - App-Install':'sum',\n",
    "#                                  'impressions_Social - Audience Content':'sum',\n",
    "#                                  'impressions_Social - Business As Usual':'sum',\n",
    "#                                  'impressions_Social - Content/Audience Development':'sum',\n",
    "#                                  'impressions_Social - DR and Content Combined':'sum',\n",
    "#                                  'impressions_Social - Gifting':'sum',\n",
    "#                                  'impressions_Social - One Day Sale':'sum',\n",
    "#                                  'impressions_Social - Sale':'sum',\n",
    "#                                  'impressions_Social - X-UNKNOWN-X':'sum',\n",
    "#                                  'impressions_Video - Business As Usual':'sum',\n",
    "#                                  'impressions_Video - One Day Sale':'sum',\n",
    "#                                  'impressions_Video - Sale':'sum',\n",
    "#                                  'impressions_X-UNKNOWN-X - Business As Usual':'sum',\n",
    "#                                  'impressions_X-UNKNOWN-X - Content/Audience Development':'sum',\n",
    "#                                  'impressions_Youtube - Content/Audience Development':'sum',\n",
    "#                                  'impressions_Youtube - X-UNKNOWN-X':'sum',\n",
    "#                                  'month_April':'max',\n",
    "#                                  'month_August':'max',\n",
    "#                                  'month_December':'max',\n",
    "#                                  'month_February':'max',\n",
    "#                                  'month_January':'max',\n",
    "#                                  'month_July':'max',\n",
    "#                                  'month_June':'max',\n",
    "#                                  'month_March':'max',\n",
    "#                                  'month_May':'max',\n",
    "#                                  'month_November':'max',\n",
    "#                                  'month_October':'max',\n",
    "#                                  'month_September':'max'\n",
    "#                                })\n",
    "\n",
    "# y = y.groupby('year_week_monday').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# scaled = scaler.fit_transform(X)\n",
    "\n",
    "# X = pd.DataFrame(data=scaled, columns=X.columns)\n",
    "# X['date'] = reg_df_reg.index.values\n",
    "# X.set_index('date', inplace=True)\n",
    "\n",
    "# y['date'] = reg_df_reg.index.values\n",
    "# y.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "\n",
    "ols_test = sm.OLS(y, X).fit() \n",
    "\n",
    "ols_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_y_pred = ols_test.predict(X)\n",
    "\n",
    "ols_vis = X.copy()\n",
    "ols_vis['y_pred'] = ols_y_pred\n",
    "ols_vis['y_actual'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='spg_convs_predicted'))\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='spg_convs_actual'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Try holding out the last few months__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_s = '2019-01-01'\n",
    "is_e = '2020-09-30'\n",
    "\n",
    "oos_s = '2020-10-01'\n",
    "oos_e = '2020-12-01'\n",
    "\n",
    "X_train = X.loc[is_s:is_e]\n",
    "X_test = X.loc[oos_s:oos_e]\n",
    "\n",
    "y_train = y.loc[is_s:is_e]\n",
    "y_test = y.loc[oos_s:oos_e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "\n",
    "ols = sm.OLS(y_train, X_train).fit() \n",
    "\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# TRAIN\n",
    "######################################\n",
    "\n",
    "train_ols_y_pred = ols.predict(X_train)\n",
    "\n",
    "train_ols_vis = X_train.copy()\n",
    "train_ols_vis['y_pred'] = train_ols_y_pred\n",
    "train_ols_vis['y_actual'] = y_train\n",
    "\n",
    "#####################################\n",
    "# TEST\n",
    "######################################\n",
    "test_ols_y_pred = ols.predict(X_test)\n",
    "\n",
    "test_ols_vis = X_test.copy()\n",
    "test_ols_vis['y_pred'] = test_ols_y_pred\n",
    "test_ols_vis['y_actual'] = y_test\n",
    "\n",
    "######################################\n",
    "# COMBINE\n",
    "######################################\n",
    "\n",
    "ols_vis = pd.concat([train_ols_vis,test_ols_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='spg_conversions_predicted'))\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='spg_conversions_actual'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = reg_df[indep_vars + ['spg_conversions_all']].loc[oos_s:oos_e]\n",
    "test = sm.add_constant(test)\n",
    "indep_vars = indep_vars + ['const']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.oos_testing(test,ols,indep_vars,oos_s,oos_e,is_s,is_e,dep='spg_conversions_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_vis['all_core_impressions'] = ols_vis[[col for col in ols_vis.columns if 'impressions' in col and 'games' not in col and 'ck_' not in col]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(ols_vis, ['games_impressions','ck_impressions','all_impressions','y_pred','y_actual'], one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Try Stepwise__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "def forward_selected(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    i = 1\n",
    "    while remaining and current_score == best_new_score:\n",
    "        print(f\"Iteration: {i}\")\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "            print(\"New best model found\")\n",
    "            print(formula)\n",
    "        i += 1\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_df = reg_df[is_s:is_e][indep_vars + ['spg_conversions_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_df.columns = stepwise_df.columns.str.replace(' ', '')\n",
    "stepwise_df.columns = stepwise_df.columns.str.replace('-','_')\n",
    "stepwise_df.columns = stepwise_df.columns.str.replace('/','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"spg_conversions_all ~ ck_impressions + games_impressions + impressions_Display_Sale + impressions_Social_BusinessAsUsual + impressions_PaidSearch_Sale + month_June + month_April + impressions_PaidSearch_Gifting + impressions_Display_Gifting + month_May + impressions_Native_Content_AudienceDevelopment + impressions_Social_Gifting + impressions_Social_Content_AudienceDevelopment + impressions_PaidSearch_BusinessAsUsual + impressions_Display_Testing + month_March + month_July + impressions_Social_X_UNKNOWN_X + impressions_Display_BusinessAsUsual + impressions_Display_Content_AudienceDevelopment + 1\"\n",
    "stepwise_model = smf.ols(formula, stepwise_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stepwise_df_test = reg_df[oos_s:oos_e][indep_vars]\n",
    "\n",
    "stepwise_df_test.columns = stepwise_df_test.columns.str.replace(' ', '')\n",
    "stepwise_df_test.columns = stepwise_df_test.columns.str.replace('-','_')\n",
    "stepwise_df_test.columns = stepwise_df_test.columns.str.replace('/','_')\n",
    "\n",
    "stepwise_df_train = reg_df[is_s:is_e][indep_vars]\n",
    "\n",
    "stepwise_df_train.columns = stepwise_df_train.columns.str.replace(' ', '')\n",
    "stepwise_df_train.columns = stepwise_df_train.columns.str.replace('-','_')\n",
    "stepwise_df_train.columns = stepwise_df_train.columns.str.replace('/','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# TRAIN\n",
    "######################################\n",
    "\n",
    "stepwise_train_y_pred = stepwise_model.predict(stepwise_df_train)\n",
    "stepwise_df_train['y_pred'] = stepwise_train_y_pred\n",
    "stepwise_df_train['y_actual'] = reg_df[is_s:is_e]['spg_conversions_all']\n",
    "\n",
    "#####################################\n",
    "# TEST\n",
    "######################################\n",
    "stepwise_test_y_pred = stepwise_model.predict(stepwise_df_test)\n",
    "stepwise_df_test['y_pred'] = stepwise_test_y_pred\n",
    "stepwise_df_test['y_actual'] = reg_df[oos_s:oos_e]['spg_conversions_all']\n",
    "\n",
    "######################################\n",
    "# COMBINE\n",
    "######################################\n",
    "\n",
    "stepwise_vis = pd.concat([stepwise_df_train,stepwise_df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(stepwise_vis, ['y_pred','y_actual'], one_plot=True, scaled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Capture basic info on cross-sell (Cooking Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Identify cross-sell patterns (CK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Look at volumes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_init_vol = df_core.groupby(['marketing_initiative'])['impressions', 'ck_conversions'].sum().sort_values('ck_conversions', ascending=False)\n",
    "mkt_init_vol.reset_index(inplace=True)\n",
    "mkt_init_vol['impression_weights'] = mkt_init_vol['impressions'] / mkt_init_vol['ck_conversions']\n",
    "mkt_init_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_init_vol.sort_values('impression_weights', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sale, Content/Audience Dev, and BAU make up the vast majority of CK cross sells. However, this is mostly because of sheer impression volume. The most efficient tactics are those with the lowest impression weights - Testing, Gifting, Audience Content, Content/Audience Dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_vol = df_core.groupby(['channel'])['impressions','ck_conversions'].sum().sort_values('ck_conversions', ascending=False)\n",
    "channel_vol.reset_index(inplace=True)\n",
    "channel_vol['impression_weights'] = channel_vol['impressions'] / channel_vol['ck_conversions']\n",
    "channel_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_vol.sort_values('impression_weights', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display, Native and Social drove the most cross-sells. But Paid Search drove the most efficient cross-sells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mkt_vol = df_core.groupby('channel_mkt_init')['impressions','ck_conversions'].sum().sort_values('ck_conversions',ascending=False)\n",
    "channel_mkt_vol.reset_index(inplace=True)\n",
    "channel_mkt_vol['impression_weights'] = channel_mkt_vol['impressions'] / channel_mkt_vol['ck_conversions']\n",
    "channel_mkt_vol.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mkt_vol.sort_values('impression_weights', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various Paid Search and Display tactics drove the most efficient cross-sell results. Meanwhile, Display Social and Native (Sale and Content/Audience Dev) drove the highest volume of cross-sells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Look at correlations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create monthly view\n",
    "df_core_monthly = df_core.groupby(['year_month_cal','channel_mkt_init'])[['clicks','impressions','games_conversions','ck_conversions']].sum().reset_index()\n",
    "\n",
    "#pivot to only have only one row per month\n",
    "df_core_monthly = df_core_monthly.pivot(index='year_month_cal', columns='channel_mkt_init', values=['clicks','impressions','games_conversions','ck_conversions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten index\n",
    "df_core_monthly.columns = df_core_monthly.columns.to_flat_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create one aggregate ck starts column for simpler correlations\n",
    "df_core_monthly['ck_conversions_all'] = df_core_monthly[[col for col in df_core_monthly.columns if 'ck_conversions' in col]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with just impressions and ck conversions\n",
    "ck_imps_monthly = df_core_monthly[[col for col in df_core_monthly.columns if 'impressions' in col] + ['ck_conversions_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nans with 0 because it means there were no impressions in that period\n",
    "ck_imps_monthly.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get correlations between ck starts and impression volumes\n",
    "ck_convs_imps_corr = ck_imps_monthly.corrwith(ck_imps_monthly['ck_conversions_all']).to_frame().rename(columns={0:'corr_with_ck_conv'}).reset_index()\n",
    "\n",
    "#sort the frame\n",
    "ck_convs_imps_corr.sort_values('corr_with_ck_conv', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ck_convs_imps_corr.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above correlation chart, it seems that __sales__ have the strongest relationship with cross-sell starts. Major channels such as Paid Search, Display, Native, and Social show the highest correlation. That said, the highest correlation by far is Paid Search - Sale; other channels have modest relationships with CK conversions (~.50 or less)\n",
    "\n",
    "This preliminary analysis would indicate that sale-based Core media does the best job attracting Cooking starts.\n",
    "\n",
    "Social - Audience/Content also seems to do a fairly good job generating CK starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_imps_monthly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Does a relationship exist?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if any of the correlations meet this threshold: \n",
    "\n",
    "\\begin{align}\n",
    "\\left | r \\right | \\geq  \\frac{2}{\\sqrt{n}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_convs_imps_corr['rel_threshold'] = 2 / np.sqrt(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ck_convs_imps_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Try a Regression (CK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cols to try: \n",
    "* campaign_objective\n",
    "* marketing_initiative\n",
    "* marketing_segment\n",
    "* channel\n",
    "* platform\n",
    "* impressions\n",
    "* core_conversions\n",
    "* month dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce number of cols \n",
    "df_reg = df_core[(df_core['channel'].isin(['Display','Native','Social','Paid Search'])) & \n",
    "                (df_core['marketing_initiative'].isin(['Sale','Content/Audience Development','Business As Usual','One Day Sale']))].groupby(['date','channel','marketing_initiative'])[['impressions','core_conversions','ck_conversions']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.groupby(['date'])[['impressions','core_conversions','ck_conversions']].sum().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create month and weekday cols for dummies\n",
    "df_reg['weekday'] = df_reg['date'].apply(lambda x: x.strftime('%A'))\n",
    "df_reg['month'] = df_reg['date'].dt.month_name()\n",
    "\n",
    "#create a merge dummies \n",
    "df_reg = pd.concat([df_reg, \n",
    "                  pd.get_dummies(df_reg['channel'], prefix='channel'),\n",
    "                 pd.get_dummies(df_reg['marketing_initiative'], prefix='mkt_init'), \n",
    "               pd.get_dummies(df_reg['weekday'], prefix='weekday'), \n",
    "               pd.get_dummies(df_reg['month'], prefix='month')], axis=1)\n",
    "\n",
    "#drop old cols and set index to date\n",
    "df_reg.drop(['channel','marketing_initiative','weekday','month'], axis=1, inplace=True)\n",
    "df_reg.set_index('date', inplace=True)\n",
    "\n",
    "# #add some holiday dummies for cooking \n",
    "# df_reg['xmas'] = 0\n",
    "# df_reg.loc['2020-12-20':'2020-12-25', 'xmas'] = 1\n",
    "\n",
    "# df_reg['thanksgiving'] = 0\n",
    "# df_reg.loc['2020-11-22':'2020-11-25', 'thanksgiving'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.groupby('date').agg({'impressions': 'sum',\n",
    "                            'core_conversions':'sum',\n",
    "                            'ck_conversions':'sum',\n",
    "                            'channel_Display':'max',\n",
    "                             'channel_Native':'max',\n",
    "                             'channel_Paid Search':'max',\n",
    "                             'channel_Social':'max',\n",
    "                             'mkt_init_Business As Usual':'max',\n",
    "                             'mkt_init_Content/Audience Development':'max',\n",
    "                             'mkt_init_One Day Sale':'max',\n",
    "                             'mkt_init_Sale':'max',\n",
    "                             'month_April':'max',\n",
    "                             'month_August':'max',\n",
    "                             'month_December':'max',\n",
    "                             'month_February':'max',\n",
    "                             'month_January':'max',\n",
    "                             'month_July':'max',\n",
    "                             'month_June':'max',\n",
    "                             'month_March':'max',\n",
    "                             'month_May':'max',\n",
    "                             'month_November':'max',\n",
    "                             'month_October':'max',\n",
    "                             'month_September':'max',\n",
    "                             'weekday_Friday':'max',\n",
    "                             'weekday_Monday':'max',\n",
    "                             'weekday_Saturday':'max',\n",
    "                             'weekday_Sunday':'max',\n",
    "                             'weekday_Thursday':'max',\n",
    "                             'weekday_Tuesday':'max',\n",
    "                             'weekday_Wednesday':'max'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reg.drop('ck_conversions', axis=1)\n",
    "y = df_reg[['ck_conversions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(data=scaled, columns=X.columns)\n",
    "X['date'] = df_reg.index.values\n",
    "X.set_index('date', inplace=True)\n",
    "\n",
    "y['date'] = df_reg.index.values\n",
    "y.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "\n",
    "ols_test = sm.OLS(y, X).fit() \n",
    "\n",
    "ols_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_y_pred = ols_test.predict(X)\n",
    "\n",
    "ols_vis = X.copy()\n",
    "ols_vis['y_pred'] = ols_y_pred\n",
    "ols_vis['y_actual'] = y\n",
    "\n",
    "ols_daily = ols_vis.reset_index().groupby('date').sum()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ols_daily.index, y=ols_daily['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_predicted'))\n",
    "fig.add_trace(go.Scatter(x=ols_daily.index, y=ols_daily['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_actual'))\n",
    "fig.add_trace(go.Scatter(x=ols_daily.index, y=ols_daily['impressions'],\n",
    "                    mode='lines',\n",
    "                    name='total_core_impressions'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scaled version of residuals plot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scaler = MinMaxScaler()\n",
    "plot_scaled = plot_scaler.fit_transform(ols_daily)\n",
    "\n",
    "\n",
    "plot_daily = pd.DataFrame(data=plot_scaled, columns=ols_daily.columns)\n",
    "plot_daily['date'] = ols_daily.index.values\n",
    "plot_daily.set_index('date', inplace=True)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_predicted'))\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_actual'))\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['impressions'],\n",
    "                    mode='lines',\n",
    "                    name='total_core_impressions'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial pass was garbage. There are likely several reasons for this, but first and foremost is that we have too many independent variables, too few observations which include those independent variables, and independent variables that have little to no relationship with our dependent (in this case, Cooking starts). \n",
    "\n",
    "To refine the regression approach we need to do more EDA to understand which channels and tactics have the most explanatory power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE: CK conversions drop to near zero in May through July, and also have major spikes around Thanksgiving and Xmas. Cooking media went dark in May through July, and also has the heaviest spend around the aforementioned holidays. The absence of Cooking starts during the dark period and the holiday spikes could indicate that these Cooking \"cross sell\" starts are really being driven by Cooking media, and the audiences also happened to be served Core ads which greedily picked up the credit. Need to explore this further - very important caveat to this analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Critical open question:__\n",
    "* How do we remove the influence of Cooking/Games paid media that ran concurrently with Core paid media?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible solution could be to __only include click-through cross-sell conversions__ in this analysis. That way we can be a little more sure that it was, in fact, the Core ad that generated the CK or Games conversion. This would be a more conservative approach, but would mitigate the risk that we go on to calculate a blended CPO based on misattributed viewthrough conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try two model improvements, separately: \n",
    "\n",
    "#### A) just look at click-thru conversions\n",
    "#### B) add in CK spend/impressions to regression and see how it correlates / comes into the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_daily = df[(df['marketing_subinitiative'] == 'Cooking') & \n",
    "  (df['attr_window'] == 'Media Reported') & \n",
    "  (df['marketing_initiative'] != 'App Download') & \n",
    "  ~(df['campaign'].str.contains('app'))]\n",
    "\n",
    "ck_daily['date'] = ck_daily['date'].astype('datetime64[ns]')\n",
    "\n",
    "ck_daily = ck_daily.groupby('date').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_daily.rename(columns = {'impressions':'ck_impressions',\n",
    "                          'spend':'ck_spend'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.reset_index(inplace=True)\n",
    "df_reg['date'] = df_reg['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.merge(ck_daily[['date','ck_impressions']], how='left', on='date').fillna(0)\n",
    "df_reg.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reg.drop('ck_conversions', axis=1)\n",
    "y = df_reg[['ck_conversions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(data=scaled, columns=X.columns)\n",
    "X['date'] = df_reg.index.values\n",
    "X.set_index('date', inplace=True)\n",
    "\n",
    "y['date'] = df_reg.index.values\n",
    "y.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "\n",
    "ols_test = sm.OLS(y, X).fit() \n",
    "\n",
    "ols_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scaler = MinMaxScaler()\n",
    "plot_scaled = plot_scaler.fit_transform(ols_daily)\n",
    "\n",
    "\n",
    "plot_daily = pd.DataFrame(data=plot_scaled, columns=ols_daily.columns)\n",
    "plot_daily['date'] = ols_daily.index.values\n",
    "plot_daily.set_index('date', inplace=True)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_predicted'))\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='ck_conversions_actual'))\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['impressions'],\n",
    "                    mode='lines',\n",
    "                    name='total_core_impressions'))\n",
    "fig.add_trace(go.Scatter(x=plot_daily.index, y=plot_daily['ck_impressions'],\n",
    "                    mode='lines',\n",
    "                    name='ck_impressions'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = df_core.groupby(['date','marketing_initiative'])[['clicks','impressions',\n",
    "                                                      'spend','core_conversions',\n",
    "                                                      'ck_conversions']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = reg_df.pivot(index='date', \n",
    "                      columns='marketing_initiative', \n",
    "                      values=['clicks','impressions','spend','core_conversions','ck_conversions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.columns = reg_df.columns = ['_'.join(col).strip() for col in reg_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.reset_index(inplace=True)\n",
    "reg_df['date'] = reg_df['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df['core_ck_conversions_all'] = reg_df[[col for col in reg_df.columns if 'ck_conversions' in col]].sum(axis=1)\n",
    "reg_df['core_core_conversions_all'] = reg_df[[col for col in reg_df.columns if 'core_conversions' in col]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create month and weekday cols for dummies\n",
    "reg_df['weekday'] = reg_df['date'].apply(lambda x: x.strftime('%A'))\n",
    "reg_df['month'] = reg_df['date'].dt.month_name()\n",
    "\n",
    "#create a merge dummies \n",
    "reg_df = pd.concat([reg_df, \n",
    "               pd.get_dummies(reg_df['weekday'], prefix='weekday'), \n",
    "               pd.get_dummies(reg_df['month'], prefix='month')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__add spg impressions, spend information__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create reg_dfs from main data pull with only cooking and games data\n",
    "\n",
    "cooking_reg_df = df[(df['marketing_subinitiative'].isin(['Cooking'])) & \n",
    "                     ~(df['campaign'].str.contains('app')) & \n",
    "                    (df['attr_window'] == 'Combined')]\n",
    "\n",
    "# games_reg_df = df[(df['marketing_subinitiative'].isin(['Games'])) & \n",
    "#                      ~(df['campaign'].str.contains('app')) & \n",
    "#                     (df['attr_window'] == 'Combined')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up date col\n",
    "cooking_reg_df['date'] = cooking_reg_df['date'].astype('datetime64[ns]')\n",
    "# games_reg_df['date'] = games_reg_df['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group cooking and games reg_dfs to daily spend, impressions + rename cols\n",
    "cooking_daily = cooking_reg_df.groupby('date')[['impressions','spend', 'ck_conversions']].sum().reset_index().rename(columns={'impressions':'ck_impressions',\n",
    "                                                                                       'spend':'ck_spend',\n",
    "                                                                                        'ck_conversions':'ck_ck_conversions'})\n",
    "# games_daily = games_reg_df.groupby('date')[['impressions','spend']].sum().reset_index().rename(columns={'impressions':'games_impressions',\n",
    "#                                                                                        'spend':'games_spend'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge cooking and games info into reg_df that we'll use for regression\n",
    "reg_df = reg_df.merge(cooking_daily, how='left', on='date')\n",
    "# reg_df = reg_df.merge(games_daily, how='left', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NA with 0\n",
    "reg_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index as date\n",
    "reg_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_vars = [col for col in reg_df.columns if 'core_conversions' in col and 'Brand' not in col and 'UNKNOWN' not in col and col != 'core_core_conversions_all'] + \\\n",
    "[col for col in reg_df.columns if 'weekday_' in col] + \\\n",
    "['ck_spend', 'ck_ck_conversions', 'ck_impressions']\n",
    "# [col for col in reg_df.columns if 'core_conversions' in col] + \\\n",
    "# [col for col in reg_df.columns if 'month_' in col] + \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reg_df[indep_vars]\n",
    "y = reg_df[['core_ck_conversions_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "\n",
    "ols_test = sm.OLS(y, X).fit() \n",
    "\n",
    "ols_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_y_pred = ols_test.predict(X)\n",
    "\n",
    "ols_vis = X.copy()\n",
    "ols_vis['y_pred'] = ols_y_pred\n",
    "ols_vis['y_actual'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='spg_convs_predicted'))\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='spg_convs_actual'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(ols_vis, ['y_pred','y_actual','ck_spend','ck_impressions',\n",
    "                        'ck_ck_conversions'], one_plot=True, scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Try holding out the last few months__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_s = '2019-01-01'\n",
    "is_e = '2020-12-31'\n",
    "\n",
    "oos_s = '2021-01-01'\n",
    "oos_e = '2021-04-01'\n",
    "\n",
    "X_train = X.loc[is_s:is_e]\n",
    "X_test = X.loc[oos_s:oos_e]\n",
    "\n",
    "y_train = y.loc[is_s:is_e]\n",
    "y_test = y.loc[oos_s:oos_e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "\n",
    "ols = sm.OLS(y_train, X_train).fit() \n",
    "\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# TRAIN\n",
    "######################################\n",
    "\n",
    "train_ols_y_pred = ols.predict(X_train)\n",
    "\n",
    "train_ols_vis = X_train.copy()\n",
    "train_ols_vis['y_pred'] = train_ols_y_pred\n",
    "train_ols_vis['y_actual'] = y_train\n",
    "\n",
    "#####################################\n",
    "# TEST\n",
    "######################################\n",
    "test_ols_y_pred = ols.predict(X_test)\n",
    "\n",
    "test_ols_vis = X_test.copy()\n",
    "test_ols_vis['y_pred'] = test_ols_y_pred\n",
    "test_ols_vis['y_actual'] = y_test\n",
    "\n",
    "######################################\n",
    "# COMBINE\n",
    "######################################\n",
    "\n",
    "ols_vis = pd.concat([train_ols_vis,test_ols_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_pred'],\n",
    "                    mode='lines',\n",
    "                    name='spg_conversions_predicted'))\n",
    "fig.add_trace(go.Scatter(x=ols_vis.index, y=ols_vis['y_actual'],\n",
    "                    mode='lines',\n",
    "                    name='spg_conversions_actual'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gradient boosting test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, ensemble\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes(as_frame=True)\n",
    "X, y = diabetes.data, diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_1 = []\n",
    "line_2 = []\n",
    "\n",
    "for x in range(0, 100): \n",
    "    line_1.append(2*x + 2)\n",
    "    line_2.append(5*x + 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame = pd.DataFrame(columns=['line_1','line_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame['line_1'] = line_1\n",
    "test_frame['line_2'] = line_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure(data=go.Scatter(x=test_frame['line_1'],\n",
    "                                y=test_frame['line_2'],\n",
    "                                mode='markers')) # hover text goes here\n",
    "\n",
    "fig.update_layout(title='Population of USA States')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame['div'] = test_frame['line_2'] / test_frame['line_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame['div'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_frame.index.values\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x,\n",
    "                y=test_frame['line_1'],\n",
    "                mode='markers')) # hover text goes here\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x,\n",
    "                y=test_frame['line_2'],\n",
    "                mode='markers')) # hover text goes here\n",
    "\n",
    "fig.update_layout(title='Arbitrary lines')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_x = test_frame['line_1']\n",
    "line_y = test_frame['line_2']\n",
    "\n",
    "line_x = sm.add_constant(line_x)\n",
    "\n",
    "\n",
    "test_frame_ols = sm.OLS(line_y, line_x).fit() \n",
    "\n",
    "test_frame_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame['ols_calc'] = test_frame['line_1'] * 2.5 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II: \"SECONDARY MULTIPLIERS\" - VIEWTHRU ESTIMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_q = '''\n",
    "SELECT \n",
    "     account\n",
    "    , attr_window\n",
    "    , campaign\n",
    "    , _match\n",
    "    , campaign_objective\n",
    "    , date\n",
    "    , marketing_initiative\n",
    "    , marketing_segment\n",
    "    , marketing_subinitiative\n",
    "    , channel\n",
    "    , platform\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then spend else 0 end) spend\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then clicks else 0 end) clicks\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then impressions else 0 end) impressions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Core' then conversions else null end) digi_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Crosswords' then conversions else null end) games_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'EDU' then conversions else null end) edu_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Home Delivery' then conversions else null end) hd_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'CK' then conversions else null end) ck_conversions     \n",
    "    , sum(case\n",
    "            when sor_prod = 'Core All (Core, HD, EDU)' then conversions else null end) core_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'All (Core All, NPV)' then conversions else null end) all_conversions\n",
    "FROM `nyt-mkt-prd.paid_media_data.placement_daily_vw`\n",
    "WHERE date >= '2016-01-01' and attr_window in('Media Reported - Click Thru')\n",
    "group by 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\n",
    "order by date, campaign, _match\n",
    "\n",
    "'''\n",
    "\n",
    "vt_q = '''\n",
    "SELECT \n",
    "     account\n",
    "    , attr_window\n",
    "    , campaign\n",
    "    , _match\n",
    "    , campaign_objective\n",
    "    , date\n",
    "    , marketing_initiative\n",
    "    , marketing_segment\n",
    "    , marketing_subinitiative\n",
    "    , channel\n",
    "    , platform\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then spend else 0 end) spend\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then clicks else 0 end) clicks\n",
    "    , sum(case when sor_prod = 'All (Core All, NPV)' then impressions else 0 end) impressions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Core' then conversions else null end) digi_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Crosswords' then conversions else null end) games_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'EDU' then conversions else null end) edu_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'Home Delivery' then conversions else null end) hd_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'CK' then conversions else null end) ck_conversions     \n",
    "    , sum(case\n",
    "            when sor_prod = 'Core All (Core, HD, EDU)' then conversions else null end) core_conversions\n",
    "    , sum(case\n",
    "            when sor_prod = 'All (Core All, NPV)' then conversions else null end) all_conversions\n",
    "FROM `nyt-mkt-prd.paid_media_data.placement_daily_vw`\n",
    "WHERE date >= '2016-01-01' and attr_window in('Media Reported - View Thru')\n",
    "group by 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\n",
    "order by date, campaign, _match\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time() \n",
    "\n",
    "clickthru_df = pd.read_gbq(ct_q,\n",
    "                 project_id ='nyt-bigquery-beta-workspace',\n",
    "                 dialect='standard',\n",
    "                 verbose=False)\n",
    "\n",
    "viewthru_df = pd.read_gbq(vt_q,\n",
    "                 project_id ='nyt-bigquery-beta-workspace',\n",
    "                 dialect='standard',\n",
    "                 verbose=False)\n",
    "\n",
    "print(f'time took: {str(round(time.time() - start_time, 2))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some Twigeo campaigns don't get recognized as Games campaigns in PMD, manually correct those\n",
    "clickthru_df.loc[(clickthru_df['marketing_subinitiative'] == 'X-UNKNOWN-X') & \n",
    "       (\n",
    "          (clickthru_df['campaign'].str.contains('game')) | \n",
    "          (clickthru_df['campaign'].str.contains('xwd')) | \n",
    "          (clickthru_df['campaign'].str.contains('cross'))\n",
    "       ), 'marketing_subinitiative'] = 'Games (former: Crosswords)'\n",
    "\n",
    "viewthru_df.loc[(viewthru_df['marketing_subinitiative'] == 'X-UNKNOWN-X') & \n",
    "       (\n",
    "          (viewthru_df['campaign'].str.contains('game')) | \n",
    "          (viewthru_df['campaign'].str.contains('xwd')) | \n",
    "          (viewthru_df['campaign'].str.contains('cross'))\n",
    "       ), 'marketing_subinitiative'] = 'Games (former: Crosswords)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add columns for easier grouping (quarter, month, week) + analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create date-based aggregation columns for easier grouping\n",
    "clickthru_df['year_month_cal'] = clickthru_df['date'].dt.strftime('%Y-%m').astype('datetime64[ns]')\n",
    "clickthru_df['year_week_monday'] = clickthru_df['date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "clickthru_df['year_quarter'] = clickthru_df['date'].dt.to_period('Q').apply(lambda r: r.start_time)\n",
    "\n",
    "viewthru_df['year_month_cal'] = viewthru_df['date'].dt.strftime('%Y-%m').astype('datetime64[ns]')\n",
    "viewthru_df['year_week_monday'] = viewthru_df['date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "viewthru_df['year_quarter'] = viewthru_df['date'].dt.to_period('Q').apply(lambda r: r.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a combined spg_conversions column from games and ck\n",
    "clickthru_df['spg_conversions'] = clickthru_df['games_conversions'] + clickthru_df['ck_conversions']\n",
    "viewthru_df['spg_conversions'] = viewthru_df['games_conversions'] + viewthru_df['ck_conversions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a composite channel-marketing-initiative column for a pd.melt\n",
    "clickthru_df['channel_mkt_init'] = clickthru_df['channel'] + \" - \" + clickthru_df['marketing_initiative']\n",
    "viewthru_df['spg_conversions'] = viewthru_df['games_conversions'] + viewthru_df['ck_conversions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_clickthru_cols = []\n",
    "for col in clickthru_df.columns:\n",
    "    if 'conversions' in col:\n",
    "        adjusted_clickthru_cols.append('clickthru_' + col)\n",
    "    else:\n",
    "        adjusted_clickthru_cols.append(col)\n",
    "\n",
    "clickthru_df.columns = adjusted_clickthru_cols\n",
    "\n",
    "\n",
    "adjusted_viewthru_cols = []\n",
    "for col in viewthru_df.columns:\n",
    "    if 'conversions' in col:\n",
    "        adjusted_viewthru_cols.append('viewthru_' + col)\n",
    "    else:\n",
    "        adjusted_viewthru_cols.append(col)\n",
    "\n",
    "viewthru_df.columns = adjusted_viewthru_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewthru_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickthru_df.merge(viewthru_df,\n",
    "                   how='left',\n",
    "                   on=['date','account','campaign','_match','campaign_objective','marketing_subinitiative',\n",
    "                      'channel','platform','spend','clicks','impressions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
